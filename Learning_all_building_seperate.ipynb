{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd02625b230b0936c03a7a859dabe4a10a429313c958b60e79e367b6eadd1f82f0b",
   "display_name": "Python 3.9.1 64-bit ('torch1': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  num           date_time       kWH     C  m/s   wet   mm   hr  \\\n",
       "0   1 2020-06-01 00:00:00  8179.056  17.6  2.5  92.0  0.8  0.0   \n",
       "1   1 2020-06-01 01:00:00  8135.640  17.7  2.9  91.0  0.3  0.0   \n",
       "2   1 2020-06-01 02:00:00  8107.128  17.5  3.2  91.0  0.0  0.0   \n",
       "3   1 2020-06-01 03:00:00  8048.808  17.1  3.2  91.0  0.0  0.0   \n",
       "4   1 2020-06-01 04:00:00  8043.624  17.0  3.3  92.0  0.0  0.0   \n",
       "\n",
       "   non_electric_aircondition  sunlight  time_idx Week 24Hour holiday Weekend  \n",
       "0                          0         0         0    1      0       0       0  \n",
       "1                          0         0         1    1      1       0       0  \n",
       "2                          0         0         2    1      2       0       0  \n",
       "3                          0         0         3    1      3       0       0  \n",
       "4                          0         0         4    1      4       0       0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num</th>\n      <th>date_time</th>\n      <th>kWH</th>\n      <th>C</th>\n      <th>m/s</th>\n      <th>wet</th>\n      <th>mm</th>\n      <th>hr</th>\n      <th>non_electric_aircondition</th>\n      <th>sunlight</th>\n      <th>time_idx</th>\n      <th>Week</th>\n      <th>24Hour</th>\n      <th>holiday</th>\n      <th>Weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2020-06-01 00:00:00</td>\n      <td>8179.056</td>\n      <td>17.6</td>\n      <td>2.5</td>\n      <td>92.0</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-06-01 01:00:00</td>\n      <td>8135.640</td>\n      <td>17.7</td>\n      <td>2.9</td>\n      <td>91.0</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2020-06-01 02:00:00</td>\n      <td>8107.128</td>\n      <td>17.5</td>\n      <td>3.2</td>\n      <td>91.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2020-06-01 03:00:00</td>\n      <td>8048.808</td>\n      <td>17.1</td>\n      <td>3.2</td>\n      <td>91.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2020-06-01 04:00:00</td>\n      <td>8043.624</td>\n      <td>17.0</td>\n      <td>3.3</td>\n      <td>92.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data = pd.read_csv(data_path, parse_dates = [\"date_time\"])\n",
    "\n",
    "data[\"time_idx\"] = 0\n",
    "data[\"month\"] = 0\n",
    "data[\"Week\"] = 0\n",
    "data[\"24Hour\"] = 0\n",
    "data[\"holiday\"] = 0\n",
    "data[\"Weekend\"] = 0\n",
    "\n",
    "data.loc[data[\"date_time\"].dt.month == 6, 'month'] = 0\n",
    "data.loc[data[\"date_time\"].dt.month == 7, 'month'] = 30\n",
    "data.loc[data[\"date_time\"].dt.month == 8, 'month'] = 61\n",
    "\n",
    "data.loc[(data[\"date_time\"].dt.month == 8) & (data[\"date_time\"].dt.day == 17) , 'holiday'] = 1\n",
    "\n",
    "data[\"time_idx\"] = data[\"date_time\"].dt.hour + data[\"date_time\"].dt.day * (24) + data[\"month\"] * 24\n",
    "data[\"time_idx\"] = data[\"time_idx\"] - min(data[\"time_idx\"])\n",
    "\n",
    "data[\"Week\"] = (data[\"date_time\"].dt.day + data[\"month\"]) % 7\n",
    "data[\"24Hour\"] = data[\"date_time\"].dt.hour\n",
    "\n",
    "data.loc[data[\"Week\"] == 6, 'Weekend'] = 1\n",
    "data.loc[data[\"Week\"] == 0, 'Weekend'] = 1\n",
    "\n",
    "data = data.drop(\"month\",axis='columns')\n",
    "\n",
    "data.rename(columns = {'전력사용량(kWh)' : 'kWH', '기온(°C)' : 'C', '풍속(m/s)' : 'm/s', '습도(%)' : 'wet', '강수량(mm)' : 'mm','일조(hr)' : 'hr', '비전기냉방설비운영' : \"non_electric_aircondition\", \"태양광보유\" : \"sunlight\"}, inplace = True)\n",
    "\n",
    "data = data.astype({'non_electric_aircondition' : int, 'sunlight' : int})\n",
    "data['num'] = data['num'].apply(str)\n",
    "data['Week'] = data['Week'].apply(str)\n",
    "data['24Hour'] = data['24Hour'].apply(str)\n",
    "data['holiday'] = data['holiday'].apply(str)\n",
    "data['Weekend'] = data['Weekend'].apply(str)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_bag = [data.loc[data[\"num\"] == str(i+1)] for i in range(60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "now building num : 59\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 256   \n",
      "3  | prescalers                         | ModuleDict                      | 208   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 8.8 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 16.1 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 14.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 455   \n",
      "----------------------------------------------------------------------------------------\n",
      "313 K     Trainable params\n",
      "0         Non-trainable params\n",
      "313 K     Total params\n",
      "1.253     Total estimated model params size (MB)\n",
      "Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s] /home/joeunchan/anaconda3/envs/torch1/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/joeunchan/anaconda3/envs/torch1/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  97%|█████████▋| 30/31 [00:08<00:00,  3.65it/s, loss=61.8, v_num=3, val_loss=171.0, train_loss_step=49.50]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 31/31 [00:08<00:00,  3.73it/s, loss=61.8, v_num=3, val_loss=68.50, train_loss_step=51.70, train_loss_epoch=77.20]\n",
      "Epoch 1:  97%|█████████▋| 30/31 [00:07<00:00,  3.76it/s, loss=45.1, v_num=3, val_loss=68.50, train_loss_step=45.40, train_loss_epoch=77.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 31/31 [00:08<00:00,  3.85it/s, loss=45.1, v_num=3, val_loss=51.00, train_loss_step=41.30, train_loss_epoch=46.50]\n",
      "Epoch 2:  97%|█████████▋| 30/31 [00:07<00:00,  3.80it/s, loss=41.4, v_num=3, val_loss=51.00, train_loss_step=39.80, train_loss_epoch=46.50]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 31/31 [00:07<00:00,  3.88it/s, loss=41.4, v_num=3, val_loss=44.70, train_loss_step=39.20, train_loss_epoch=41.60]\n",
      "Epoch 3:  97%|█████████▋| 30/31 [00:08<00:00,  3.64it/s, loss=38.8, v_num=3, val_loss=44.70, train_loss_step=38.80, train_loss_epoch=41.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 31/31 [00:08<00:00,  3.74it/s, loss=38.8, v_num=3, val_loss=36.70, train_loss_step=38.60, train_loss_epoch=39.30]\n",
      "Epoch 4:  97%|█████████▋| 30/31 [00:08<00:00,  3.72it/s, loss=36.6, v_num=3, val_loss=36.70, train_loss_step=36.40, train_loss_epoch=39.30]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 31/31 [00:08<00:00,  3.81it/s, loss=36.6, v_num=3, val_loss=35.70, train_loss_step=35.20, train_loss_epoch=37.20]\n",
      "Epoch 5:  97%|█████████▋| 30/31 [00:08<00:00,  3.61it/s, loss=34.4, v_num=3, val_loss=35.70, train_loss_step=33.40, train_loss_epoch=37.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 31/31 [00:08<00:00,  3.70it/s, loss=34.4, v_num=3, val_loss=33.90, train_loss_step=34.20, train_loss_epoch=35.00]\n",
      "Epoch 6:  97%|█████████▋| 30/31 [00:08<00:00,  3.67it/s, loss=32.8, v_num=3, val_loss=33.90, train_loss_step=31.30, train_loss_epoch=35.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 31/31 [00:08<00:00,  3.77it/s, loss=32.8, v_num=3, val_loss=36.80, train_loss_step=32.00, train_loss_epoch=33.10]\n",
      "Epoch 7:  97%|█████████▋| 30/31 [00:08<00:00,  3.67it/s, loss=31, v_num=3, val_loss=36.80, train_loss_step=31.40, train_loss_epoch=33.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 31/31 [00:08<00:00,  3.76it/s, loss=31, v_num=3, val_loss=34.30, train_loss_step=30.30, train_loss_epoch=31.20]\n",
      "Epoch 8:  97%|█████████▋| 30/31 [00:08<00:00,  3.60it/s, loss=30, v_num=3, val_loss=34.30, train_loss_step=29.30, train_loss_epoch=31.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 31/31 [00:08<00:00,  3.69it/s, loss=30, v_num=3, val_loss=38.10, train_loss_step=29.40, train_loss_epoch=30.00]\n",
      "Epoch 9:  97%|█████████▋| 30/31 [00:08<00:00,  3.67it/s, loss=28.9, v_num=3, val_loss=38.10, train_loss_step=29.80, train_loss_epoch=30.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 31/31 [00:08<00:00,  3.75it/s, loss=28.9, v_num=3, val_loss=38.90, train_loss_step=28.70, train_loss_epoch=29.10]\n",
      "Epoch 10:  97%|█████████▋| 30/31 [00:08<00:00,  3.71it/s, loss=27.9, v_num=3, val_loss=38.90, train_loss_step=27.40, train_loss_epoch=29.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 31/31 [00:08<00:00,  3.80it/s, loss=27.9, v_num=3, val_loss=40.00, train_loss_step=27.30, train_loss_epoch=28.10]\n",
      "Epoch 11:  97%|█████████▋| 30/31 [00:08<00:00,  3.53it/s, loss=27.2, v_num=3, val_loss=40.00, train_loss_step=27.20, train_loss_epoch=28.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 31/31 [00:08<00:00,  3.61it/s, loss=27.2, v_num=3, val_loss=41.90, train_loss_step=27.80, train_loss_epoch=27.10]\n",
      "Epoch 12:  97%|█████████▋| 30/31 [00:08<00:00,  3.63it/s, loss=26.8, v_num=3, val_loss=41.90, train_loss_step=26.40, train_loss_epoch=27.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 31/31 [00:08<00:00,  3.72it/s, loss=26.8, v_num=3, val_loss=42.10, train_loss_step=27.30, train_loss_epoch=26.90]\n",
      "Epoch 13:  97%|█████████▋| 30/31 [00:08<00:00,  3.59it/s, loss=26.9, v_num=3, val_loss=42.10, train_loss_step=26.20, train_loss_epoch=26.90]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 31/31 [00:08<00:00,  3.68it/s, loss=26.9, v_num=3, val_loss=43.10, train_loss_step=26.50, train_loss_epoch=26.80]\n",
      "Epoch 14:  97%|█████████▋| 30/31 [00:08<00:00,  3.59it/s, loss=26.6, v_num=3, val_loss=43.10, train_loss_step=26.10, train_loss_epoch=26.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 31/31 [00:08<00:00,  3.69it/s, loss=26.6, v_num=3, val_loss=43.40, train_loss_step=28.00, train_loss_epoch=26.60]\n",
      "Epoch 15:  97%|█████████▋| 30/31 [00:08<00:00,  3.65it/s, loss=26.3, v_num=3, val_loss=43.40, train_loss_step=26.50, train_loss_epoch=26.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 31/31 [00:08<00:00,  3.74it/s, loss=26.3, v_num=3, val_loss=44.50, train_loss_step=27.00, train_loss_epoch=26.30]\n",
      "Epoch 15: 100%|██████████| 31/31 [00:08<00:00,  3.74it/s, loss=26.3, v_num=3, val_loss=44.50, train_loss_step=27.00, train_loss_epoch=26.30]\n"
     ]
    }
   ],
   "source": [
    "for p in [59]: # range(0,5):\n",
    "# 34, 40, 42, 41, 4, 10, 11, 12\n",
    "    p = p-1\n",
    "\n",
    "    data = data_bag[p]\n",
    "\n",
    "    print(f\"now building num : {data.iloc[0]['num']}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    max_prediction_length = 24\n",
    "    max_encoder_length = 168\n",
    "    training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "    training = TimeSeriesDataSet(\n",
    "        data[lambda x: x.time_idx <= training_cutoff],\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"kWH\",\n",
    "        group_ids=[\"num\"],\n",
    "        min_encoder_length=max_encoder_length//2,\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=3,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=[\"num\"],\n",
    "        static_reals=[\"non_electric_aircondition\", \"sunlight\"],\n",
    "        time_varying_known_categoricals=[\"Week\", \"24Hour\", \"holiday\", \"Weekend\"],\n",
    "        time_varying_known_reals=[\"C\", \"m/s\", \"wet\", \"mm\", \"hr\", \"time_idx\"],\n",
    "        time_varying_unknown_categoricals=[],\n",
    "        time_varying_unknown_reals=[\"kWH\"],\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "    )\n",
    "\n",
    "    # create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "    # for each series\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "    # create dataloaders for model\n",
    "    batch_size = 64  # set this between 32 to 128\n",
    "    train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "    # configure network and trainer\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "    lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "    logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=500,\n",
    "        gpus=1,\n",
    "        weights_summary=\"top\",\n",
    "        gradient_clip_val=0.14,\n",
    "        limit_train_batches=30, \n",
    "        callbacks=[lr_logger, early_stop_callback],\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "\n",
    "    tft = TemporalFusionTransformer.from_dataset(\n",
    "        training,\n",
    "        learning_rate=0.01,\n",
    "        hidden_size=64,\n",
    "        lstm_layers = 2,\n",
    "        attention_head_size=4,\n",
    "        dropout=0.15,\n",
    "        hidden_continuous_size=8,\n",
    "        output_size=7,\n",
    "        loss=QuantileLoss(),# SMAPE(),\n",
    "        log_interval=0,\n",
    "        reduce_on_plateau_patience=4,\n",
    "    )\n",
    "\n",
    "    # fit network\n",
    "    trainer.fit(\n",
    "        tft,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )"
   ]
  }
 ]
}