{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd02625b230b0936c03a7a859dabe4a10a429313c958b60e79e367b6eadd1f82f0b",
   "display_name": "Python 3.9.1 64-bit ('torch1': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path, parse_dates = [\"date_time\"])\n",
    "\n",
    "data[\"time_idx\"] = 0\n",
    "data[\"month\"] = 0\n",
    "data[\"Week\"] = 0\n",
    "data[\"24Hour\"] = 0\n",
    "\n",
    "data.loc[data[\"date_time\"].dt.month == 6, 'month'] = 0\n",
    "data.loc[data[\"date_time\"].dt.month == 7, 'month'] = 30\n",
    "data.loc[data[\"date_time\"].dt.month == 8, 'month'] = 61\n",
    "\n",
    "data[\"time_idx\"] = data[\"date_time\"].dt.hour + data[\"date_time\"].dt.day * (24) + data[\"month\"] * 24\n",
    "data[\"time_idx\"] = data[\"time_idx\"] - min(data[\"time_idx\"])\n",
    "\n",
    "data[\"Week\"] = (data[\"date_time\"].dt.day + data[\"month\"]) % 7\n",
    "data[\"24Hour\"] = data[\"date_time\"].dt.hour\n",
    "\n",
    "data = data.drop(\"month\",axis='columns')\n",
    "\n",
    "data.rename(columns = {'전력사용량(kWh)' : 'kWH', '기온(°C)' : 'C', '풍속(m/s)' : 'm/s', '습도(%)' : 'wet', '강수량(mm)' : 'mm','일조(hr)' : 'hr', '비전기냉방설비운영' : \"non_electric_aircondition\", \"태양광보유\" : \"sunlight\"}, inplace = True)\n",
    "\n",
    "data = data.astype({'non_electric_aircondition' : int, 'sunlight' : int})\n",
    "data['num'] = data['num'].apply(str)\n",
    "data['Week'] = data['Week'].apply(str)\n",
    "data['24Hour'] = data['24Hour'].apply(str)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_bag = [data.loc[data[\"num\"] == str(i+1)] for i in range(60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for p in range(0,5):\n",
    "\n",
    "    data = data_bag[p]\n",
    "\n",
    "    print(f\"now building num : {data.iloc[0]['num']}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    max_prediction_length = 24\n",
    "    max_encoder_length = 168\n",
    "    training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "    training = TimeSeriesDataSet(\n",
    "        data[lambda x: x.time_idx <= training_cutoff],\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"kWH\",\n",
    "        group_ids=[\"num\"],\n",
    "        min_encoder_length=max_encoder_length//2,\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=3,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=[\"num\"],\n",
    "        static_reals=[\"non_electric_aircondition\", \"sunlight\"],\n",
    "        time_varying_known_categoricals=[\"Week\", \"24Hour\"],\n",
    "        time_varying_known_reals=[\"C\", \"m/s\", \"wet\", \"mm\", \"hr\", \"time_idx\"],\n",
    "        time_varying_unknown_categoricals=[],\n",
    "        time_varying_unknown_reals=[\"kWH\"],\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "    )\n",
    "\n",
    "    # create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "    # for each series\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "    # create dataloaders for model\n",
    "    batch_size = 64  # set this between 32 to 128\n",
    "    train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "    # configure network and trainer\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=50, verbose=False, mode=\"min\")\n",
    "    lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "    logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=500,\n",
    "        gpus=1,\n",
    "        weights_summary=\"top\",\n",
    "        gradient_clip_val=0.14,\n",
    "        limit_train_batches=30, \n",
    "        callbacks=[lr_logger, early_stop_callback],\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "\n",
    "    tft = TemporalFusionTransformer.from_dataset(\n",
    "        training,\n",
    "        learning_rate=0.03,\n",
    "        hidden_size=64,\n",
    "        attention_head_size=4,\n",
    "        dropout=0.15,\n",
    "        hidden_continuous_size=8,\n",
    "        output_size=7,\n",
    "        loss=QuantileLoss(),\n",
    "        log_interval=0,\n",
    "        reduce_on_plateau_patience=4,\n",
    "    )\n",
    "\n",
    "    # fit network\n",
    "    trainer.fit(\n",
    "        tft,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )"
   ]
  }
 ]
}