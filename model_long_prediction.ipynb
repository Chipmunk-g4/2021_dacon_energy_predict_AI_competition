{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd02625b230b0936c03a7a859dabe4a10a429313c958b60e79e367b6eadd1f82f0b",
   "display_name": "Python 3.9.1 64-bit ('torch1': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [\"Save_File/seperate_model_6hour_05_31/A.ckpt\",\n",
    "                \"Save_File/seperate_model_6hour_05_31/B.ckpt\",\n",
    "                \"Save_File/seperate_model_6hour_05_31/C.ckpt\",\n",
    "                \"Save_File/seperate_model_6hour_05_31/D.ckpt\",\n",
    "                \"Save_File/seperate_model_6hour_05_31/E.ckpt\"]\n",
    "\n",
    "# model_paths = [\"Save_File/seperate_model_24hour_05_31/A.ckpt\",\n",
    "#                 \"Save_File/seperate_model_24hour_05_31/B.ckpt\",\n",
    "#                 \"Save_File/seperate_model_24hour_05_31/C.ckpt\",\n",
    "#                 \"Save_File/seperate_model_24hour_05_31/D.ckpt\",\n",
    "#                 \"Save_File/seperate_model_24hour_05_31/E.ckpt\"]\n",
    "\n",
    "# model_paths = [\"Save_File/seperate_model_best_05_28/A/checkpoints/epoch=39-step=1199.ckpt\",\n",
    "#                 \"Save_File/seperate_model_best_05_28/B/checkpoints/epoch=57-step=1739.ckpt\",\n",
    "#                 \"Save_File/seperate_model_best_05_28/C/checkpoints/epoch=41-step=1259.ckpt\",\n",
    "#                 \"Save_File/seperate_model_best_05_28/D/checkpoints/epoch=44-step=1349.ckpt\",\n",
    "#                 \"Save_File/seperate_model_best_05_28/E/checkpoints/epoch=40-step=1229.ckpt\"]\n",
    "\n",
    "input_length = 168\n",
    "output_length = 6\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "group_name = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "\n",
    "for i in range(len(group_name)):\n",
    "    dataset = pd.read_csv(f\"Refined_Data/Grouped_Data/{group_name[i]}.csv\", index_col=0)\n",
    "    dataframes.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = [\n",
    "    [34, 40, 42, 41, 4, 10, 11, 12],\n",
    "    [35, 6, 48, 27, 57, 8, 25, 56, 26, 55, 47, 13, 53, 18, 7, 17, 46],\n",
    "    [31, 33, 9, 3, 1, 32],\n",
    "    [29, 38, 43, 58, 15, 22, 39, 54, 23, 44, 45, 37, 52, 2, 14],\n",
    "    [21, 19, 50, 49, 20, 51, 30, 36, 28, 59, 5, 60, 16, 24]\n",
    "]\n",
    "\n",
    "random_choice = 12 # random.randrange(2,13)\n",
    "\n",
    "start_point = -168 * random_choice - 1\n",
    "duration = 168\n",
    "\n",
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "\n",
    "all_smape = []\n",
    "part_smape = [[],[],[],[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10.431018455066248\n",
      "8.655864623901136\n",
      "13.137274888721418\n",
      "8.336362169783818\n",
      "21.326386879300546\n",
      "3.831519751474167\n",
      "4.1620519670405445\n",
      "6.2893990705878\n",
      "10.462290807597455\n",
      "6.21513134499569\n",
      "13.394667194045695\n",
      "16.935773686914242\n",
      "8.877728063591507\n",
      "5.323950950163385\n",
      "8.920937539137121\n",
      "9.797729316809589\n",
      "8.608966406926243\n",
      "5.627761370456362\n",
      "3.834587057271714\n",
      "7.675635457672593\n",
      "14.340592596140691\n",
      "13.529864870052853\n",
      "10.92157208819844\n",
      "7.829063876307937\n",
      "9.39841196102681\n",
      "2.1758349562763244\n",
      "1.7779051316050178\n",
      "4.520041446212153\n",
      "1.0766312551763568\n",
      "0.8438165843528204\n",
      "0.6604558372126648\n",
      "8.425258974238119\n",
      "5.658616776090621\n",
      "5.149467734115522\n",
      "4.459954378133337\n",
      "14.15730279625681\n",
      "5.985083992807871\n",
      "7.698031955272783\n",
      "3.0697955899022986\n",
      "4.746940061624305\n",
      "3.763813323875667\n",
      "13.804147803891999\n",
      "9.410020936929667\n",
      "5.303910037402687\n",
      "2.598428372717446\n",
      "7.668461863138704\n",
      "6.210793820231576\n",
      "9.30661862416872\n",
      "8.179805355512723\n",
      "6.179110730179635\n",
      "6.548176865693888\n",
      "3.6298452817595805\n",
      "6.553114102286887\n",
      "4.131015953668031\n",
      "5.801398098974738\n",
      "12.345013204566548\n",
      "9.346595710102335\n",
      "3.659109698087542\n",
      "3.597825430879956\n",
      "12.110710784520558\n",
      "\n",
      "\n",
      "selected time slice : 12\n",
      "totoal score : 7.473626597684165\n",
      "A score : 9.52123472573446\n",
      "B score : 9.511450858076959\n",
      "C score : 1.8424475351392229\n",
      "D score : 6.793282306426523\n",
      "E score : 6.971366690045194\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model_paths)):\n",
    "    now_dataframe = dataframes[i]\n",
    "    now_dataframe['num'] = now_dataframe['num'].apply(str)\n",
    "    now_dataframe['energy_group'] = now_dataframe['energy_group'].apply(str)\n",
    "    now_dataframe['Week'] = now_dataframe['Week'].apply(str)\n",
    "    now_dataframe['24Hour'] = now_dataframe['24Hour'].apply(str)\n",
    "    \n",
    "    now_best_tft = TemporalFusionTransformer.load_from_checkpoint(model_paths[i])\n",
    "\n",
    "    for building in group[i]:\n",
    "        now_building_dataframe = now_dataframe.loc[now_dataframe[\"num\"] == str(building)].copy()\n",
    "        now_building_dataframe = now_building_dataframe[start_point:start_point+input_length+duration]\n",
    "\n",
    "        original = now_building_dataframe.iloc[0:input_length+output_length][\"kWH\"].tolist()\n",
    "        prediction = now_building_dataframe.iloc[0:input_length+output_length][\"kWH\"].tolist()  \n",
    "\n",
    "        total_cycle = (len(now_building_dataframe) - input_length - output_length) // output_length\n",
    "\n",
    "        for k in range(total_cycle):\n",
    "            now_start_point = k*output_length\n",
    "\n",
    "            encoder_data = now_building_dataframe.iloc[now_start_point:now_start_point+input_length].copy()\n",
    "            decoder_data = now_building_dataframe.iloc[now_start_point+input_length:now_start_point+input_length+output_length].copy()\n",
    "            new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)\n",
    "\n",
    "            raw_predictions = now_best_tft.predict(new_prediction_data, mode=\"prediction\").numpy().tolist()[0]\n",
    "            originals = now_building_dataframe.iloc[now_start_point+input_length : now_start_point+input_length+output_length][\"kWH\"].tolist()\n",
    "\n",
    "            prediction.extend(raw_predictions)\n",
    "            original.extend(originals)\n",
    "\n",
    "            # for next step, change dataframe's original value to predicted value\n",
    "            for p in range(output_length):\n",
    "                now_building_dataframe.iloc[now_start_point+input_length+p, now_building_dataframe.columns.get_loc(\"kWH\")] = raw_predictions[p]\n",
    "            \n",
    "        # plt.rcParams[\"figure.figsize\"] = (30,10)\n",
    "        # fig = plt.figure()\n",
    "        # graph = fig.add_subplot(1, 1, 1)\n",
    "        # graph.plot(original, color='red')\n",
    "        # graph.plot(prediction, color='blue')\n",
    "        # plt.show()\n",
    "\n",
    "        smape_loss = smape(np.array(prediction[168:]), np.array(original[168:]))\n",
    "        print(smape_loss)\n",
    "        all_smape.append(smape_loss)\n",
    "        part_smape[i].append(smape_loss)\n",
    "\n",
    "        # break\n",
    "    # break\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"selected time slice : {random_choice}\")\n",
    "print(f\"totoal score : {np.mean(np.array(all_smape))}\")\n",
    "print(f\"A score : {np.mean(np.array(part_smape[0]))}\")\n",
    "print(f\"B score : {np.mean(np.array(part_smape[1]))}\")\n",
    "print(f\"C score : {np.mean(np.array(part_smape[2]))}\")\n",
    "print(f\"D score : {np.mean(np.array(part_smape[3]))}\")\n",
    "print(f\"E score : {np.mean(np.array(part_smape[4]))}\")"
   ]
  }
 ]
}