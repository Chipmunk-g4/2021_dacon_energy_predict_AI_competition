{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [\"Save_File/seperate_model_holi_wkend_05_31/A.ckpt\",\n",
    "                \"Save_File/seperate_model_deep_32_2_06_01/B.ckpt\",\n",
    "                \"Save_File/seperate_model_holi_wkend_05_31/C.ckpt\",\n",
    "                \"Save_File/seperate_model_deep_256_2_06_01/D.ckpt\",\n",
    "                \"Save_File/seperate_model_deep_32_2_06_01/E.ckpt\"]\n",
    "\n",
    "# model_paths = [\"Save_File/seperate_model_deep_256_2_06_01/A.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_256_2_06_01/B.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_256_2_06_01/C.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_256_2_06_01/D.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_256_2_06_01/E.ckpt\"]\n",
    "\n",
    "# model_paths = [\"Save_File/seperate_model_deep_128_2_05_31/A.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_128_2_05_31/B.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_128_2_05_31/C.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_128_2_05_31/D.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_128_2_05_31/E.ckpt\"]\n",
    "\n",
    "# model_paths = [\"Save_File/seperate_model_holi_wkend_05_31/A.ckpt\",\n",
    "#                 \"Save_File/seperate_model_holi_wkend_05_31/B.ckpt\",\n",
    "#                 \"Save_File/seperate_model_holi_wkend_05_31/C.ckpt\",\n",
    "#                 \"Save_File/seperate_model_holi_wkend_05_31/D.ckpt\",\n",
    "#                 \"Save_File/seperate_model_holi_wkend_05_31/E.ckpt\"]\n",
    "\n",
    "# model_paths = [\"Save_File/seperate_model_deep_32_2_06_01/A.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_32_2_06_01/B.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_32_2_06_01/C.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_32_2_06_01/D.ckpt\",\n",
    "#                 \"Save_File/seperate_model_deep_32_2_06_01/E.ckpt\"]\n",
    "\n",
    "# model_paths = [\"Save_File/seperate_model_24hour_05_31/A.ckpt\",\n",
    "#                 \"Save_File/seperate_model_24hour_05_31/B.ckpt\",\n",
    "#                 \"Save_File/seperate_model_24hour_05_31/C.ckpt\",\n",
    "#                 \"Save_File/seperate_model_24hour_05_31/D.ckpt\",\n",
    "#                 \"Save_File/seperate_model_24hour_05_31/E.ckpt\"]\n",
    "\n",
    "# model_paths = [\"Save_File/seperate_model_best_05_28/A/checkpoints/epoch=39-step=1199.ckpt\",\n",
    "#                 \"Save_File/seperate_model_best_05_28/B/checkpoints/epoch=57-step=1739.ckpt\",\n",
    "#                 \"Save_File/seperate_model_best_05_28/C/checkpoints/epoch=41-step=1259.ckpt\",\n",
    "#                 \"Save_File/seperate_model_best_05_28/D/checkpoints/epoch=44-step=1349.ckpt\",\n",
    "#                 \"Save_File/seperate_model_best_05_28/E/checkpoints/epoch=40-step=1229.ckpt\"]\n",
    "\n",
    "input_length = 168\n",
    "output_length = 24\n",
    "\n",
    "show_graph = False\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "group_name = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "\n",
    "for i in range(len(group_name)):\n",
    "    dataset = pd.read_csv(f\"Refined_Data/Grouped_Data/{group_name[i]}.csv\", index_col=0)\n",
    "    dataframes.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = [\n",
    "    [34, 40, 42, 41, 4, 10, 11, 12],\n",
    "    [35, 6, 48, 27, 57, 8, 25, 56, 26, 55, 47, 13, 53, 18, 7, 17, 46],\n",
    "    [31, 33, 9, 3, 1, 32],\n",
    "    [29, 38, 43, 58, 15, 22, 39, 54, 23, 44, 45, 37, 52, 2, 14],\n",
    "    [21, 19, 50, 49, 20, 51, 30, 36, 28, 59, 5, 60, 16, 24]\n",
    "]\n",
    "\n",
    "random_choice = 12 # random.randrange(2,13)\n",
    "\n",
    "start_point = -168 * random_choice - 1\n",
    "duration = 168\n",
    "\n",
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "\n",
    "all_smape = []\n",
    "part_smape = [[],[],[],[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "now group : A\n",
      "building : 34, score : 10.578448677724328\n",
      "building : 40, score : 7.058532900358268\n",
      "building : 42, score : 10.347361070810594\n",
      "building : 41, score : 7.372664228000604\n",
      "building : 4, score : 16.621383412685883\n",
      "building : 10, score : 5.038387285833134\n",
      "building : 11, score : 4.218974759875983\n",
      "building : 12, score : 4.295090179025246\n",
      "\n",
      "\n",
      "selected time slice : 12\n",
      "totoal score : 8.191355314289254\n",
      "A score : 8.191355314289254\n",
      "B score : nan\n",
      "C score : nan\n",
      "D score : nan\n",
      "E score : nan\n",
      "/home/joeunchan/anaconda3/envs/torch1/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/joeunchan/anaconda3/envs/torch1/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model_paths)):\n",
    "    now_dataframe = dataframes[i]\n",
    "    now_dataframe['num'] = now_dataframe['num'].apply(str)\n",
    "    now_dataframe['energy_group'] = now_dataframe['energy_group'].apply(str)\n",
    "    now_dataframe['Week'] = now_dataframe['Week'].apply(str)\n",
    "    now_dataframe['24Hour'] = now_dataframe['24Hour'].apply(str)\n",
    "    now_dataframe['holiday'] = now_dataframe['holiday'].apply(str)\n",
    "    now_dataframe['Weekend'] = now_dataframe['Weekend'].apply(str)\n",
    "    \n",
    "    now_best_tft = TemporalFusionTransformer.load_from_checkpoint(model_paths[i])\n",
    "\n",
    "    print(f\"now group : {group_name[i]}\")\n",
    "\n",
    "    for building in group[i]:\n",
    "        now_building_dataframe = now_dataframe.loc[now_dataframe[\"num\"] == str(building)].copy()\n",
    "        now_building_dataframe = now_building_dataframe[start_point:start_point+input_length+duration]\n",
    "\n",
    "        original = now_building_dataframe.iloc[0:input_length+output_length][\"kWH\"].tolist()\n",
    "        prediction = now_building_dataframe.iloc[0:input_length+output_length][\"kWH\"].tolist()  \n",
    "\n",
    "        total_cycle = (len(now_building_dataframe) - input_length - output_length) // output_length\n",
    "\n",
    "        for k in range(total_cycle):\n",
    "            now_start_point = k*output_length\n",
    "\n",
    "            encoder_data = now_building_dataframe.iloc[now_start_point:now_start_point+input_length].copy()\n",
    "            decoder_data = now_building_dataframe.iloc[now_start_point+input_length:now_start_point+input_length+output_length].copy()\n",
    "            new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)\n",
    "\n",
    "            raw_predictions = now_best_tft.predict(new_prediction_data, mode=\"prediction\").numpy().tolist()[0]\n",
    "            originals = now_building_dataframe.iloc[now_start_point+input_length : now_start_point+input_length+output_length][\"kWH\"].tolist()\n",
    "\n",
    "            prediction.extend(raw_predictions)\n",
    "            original.extend(originals)\n",
    "\n",
    "            # for next step, change dataframe's original value to predicted value\n",
    "            for p in range(output_length):\n",
    "                now_building_dataframe.iloc[now_start_point+input_length+p, now_building_dataframe.columns.get_loc(\"kWH\")] = raw_predictions[p]\n",
    "            \n",
    "        if show_graph:\n",
    "            plt.rcParams[\"figure.figsize\"] = (30,10)\n",
    "            fig = plt.figure()\n",
    "            graph = fig.add_subplot(1, 1, 1)\n",
    "            graph.plot(original, color='red')\n",
    "            graph.plot(prediction, color='blue')\n",
    "            plt.show()\n",
    "\n",
    "        smape_loss = smape(np.array(prediction[168:]), np.array(original[168:]))\n",
    "        print(f\"building : {building}, score : {smape_loss}\")\n",
    "        all_smape.append(smape_loss)\n",
    "        part_smape[i].append(smape_loss)\n",
    "\n",
    "        # break\n",
    "    break\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"selected time slice : {random_choice}\")\n",
    "print(f\"totoal score : {np.mean(np.array(all_smape))}\")\n",
    "print(f\"A score : {np.mean(np.array(part_smape[0]))}\")\n",
    "print(f\"B score : {np.mean(np.array(part_smape[1]))}\")\n",
    "print(f\"C score : {np.mean(np.array(part_smape[2]))}\")\n",
    "print(f\"D score : {np.mean(np.array(part_smape[3]))}\")\n",
    "print(f\"E score : {np.mean(np.array(part_smape[4]))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd02625b230b0936c03a7a859dabe4a10a429313c958b60e79e367b6eadd1f82f0b",
   "display_name": "Python 3.9.1 64-bit ('torch1': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}