{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/train.csv\"\n",
    "\n",
    "group = [\n",
    "    [34, 40, 42, 41, 4, 10, 11, 12],\n",
    "    [35, 6, 48, 27, 57, 8, 25, 56, 26, 55, 47, 13, 53, 18, 7, 17, 46],\n",
    "    [31, 33, 9, 3, 1, 32],\n",
    "    [29, 38, 43, 58, 15, 22, 39, 54, 23, 44, 45, 37, 52, 2, 14],\n",
    "    [21, 19, 50, 49, 20, 51, 30, 36, 28, 59, 5, 60, 16, 24]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num</th>\n      <th>date_time</th>\n      <th>kWH</th>\n      <th>C</th>\n      <th>m/s</th>\n      <th>wet</th>\n      <th>mm</th>\n      <th>hr</th>\n      <th>non_electric_aircondition</th>\n      <th>sunlight</th>\n      <th>time_idx</th>\n      <th>energy_group</th>\n      <th>Week</th>\n      <th>24Hour</th>\n      <th>holiday</th>\n      <th>Weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2020-06-01 00:00:00</td>\n      <td>8179.056</td>\n      <td>17.6</td>\n      <td>2.5</td>\n      <td>92.0</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-06-01 01:00:00</td>\n      <td>8135.640</td>\n      <td>17.7</td>\n      <td>2.9</td>\n      <td>91.0</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2020-06-01 02:00:00</td>\n      <td>8107.128</td>\n      <td>17.5</td>\n      <td>3.2</td>\n      <td>91.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2020-06-01 03:00:00</td>\n      <td>8048.808</td>\n      <td>17.1</td>\n      <td>3.2</td>\n      <td>91.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2020-06-01 04:00:00</td>\n      <td>8043.624</td>\n      <td>17.0</td>\n      <td>3.3</td>\n      <td>92.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  num           date_time       kWH     C  m/s   wet   mm   hr  \\\n0   1 2020-06-01 00:00:00  8179.056  17.6  2.5  92.0  0.8  0.0   \n1   1 2020-06-01 01:00:00  8135.640  17.7  2.9  91.0  0.3  0.0   \n2   1 2020-06-01 02:00:00  8107.128  17.5  3.2  91.0  0.0  0.0   \n3   1 2020-06-01 03:00:00  8048.808  17.1  3.2  91.0  0.0  0.0   \n4   1 2020-06-01 04:00:00  8043.624  17.0  3.3  92.0  0.0  0.0   \n\n   non_electric_aircondition  sunlight  time_idx energy_group Week 24Hour  \\\n0                          0         0         0            3    1      0   \n1                          0         0         1            3    1      1   \n2                          0         0         2            3    1      2   \n3                          0         0         3            3    1      3   \n4                          0         0         4            3    1      4   \n\n  holiday Weekend  \n0       0       0  \n1       0       0  \n2       0       0  \n3       0       0  \n4       0       0  "
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path, parse_dates = [\"date_time\"])\r\n",
    "\r\n",
    "data[\"time_idx\"] = 0\r\n",
    "data[\"month\"] = 0\r\n",
    "data[\"energy_group\"] = 0\r\n",
    "data[\"Week\"] = 0\r\n",
    "data[\"24Hour\"] = 0\r\n",
    "data[\"holiday\"] = 0\r\n",
    "data[\"Weekend\"] = 0\r\n",
    "\r\n",
    "data.loc[data[\"num\"].isin(group[0]), \"energy_group\"] = str(1)\r\n",
    "data.loc[data[\"num\"].isin(group[1]), \"energy_group\"] = str(2)\r\n",
    "data.loc[data[\"num\"].isin(group[2]), \"energy_group\"] = str(3)\r\n",
    "data.loc[data[\"num\"].isin(group[3]), \"energy_group\"] = str(4)\r\n",
    "data.loc[data[\"num\"].isin(group[4]), \"energy_group\"] = str(5)\r\n",
    "\r\n",
    "data.loc[data[\"date_time\"].dt.month == 6, 'month'] = 0\r\n",
    "data.loc[data[\"date_time\"].dt.month == 7, 'month'] = 30\r\n",
    "data.loc[data[\"date_time\"].dt.month == 8, 'month'] = 61\r\n",
    "\r\n",
    "data.loc[(data[\"date_time\"].dt.month == 8) & (data[\"date_time\"].dt.day == 17) , 'holiday'] = 1\r\n",
    "\r\n",
    "data[\"time_idx\"] = data[\"date_time\"].dt.hour + data[\"date_time\"].dt.day * (24) + data[\"month\"] * 24\r\n",
    "data[\"time_idx\"] = data[\"time_idx\"] - min(data[\"time_idx\"])\r\n",
    "\r\n",
    "data[\"Week\"] = (data[\"date_time\"].dt.day + data[\"month\"]) % 7\r\n",
    "data[\"24Hour\"] = data[\"date_time\"].dt.hour\r\n",
    "\r\n",
    "data.loc[data[\"Week\"] == 6, 'Weekend'] = 1\r\n",
    "data.loc[data[\"Week\"] == 0, 'Weekend'] = 1\r\n",
    "\r\n",
    "data = data.drop(\"month\",axis='columns')\r\n",
    "\r\n",
    "data.rename(columns = {'전력사용량(kWh)' : 'kWH', '기온(°C)' : 'C', '풍속(m/s)' : 'm/s', '습도(%)' : 'wet', '강수량(mm)' : 'mm','일조(hr)' : 'hr', '비전기냉방설비운영' : \"non_electric_aircondition\", \"태양광보유\" : \"sunlight\"}, inplace = True)\r\n",
    "\r\n",
    "data = data.astype({'non_electric_aircondition' : int, 'sunlight' : int})\r\n",
    "data['num'] = data['num'].apply(str)\r\n",
    "data['Week'] = data['Week'].apply(str)\r\n",
    "data['24Hour'] = data['24Hour'].apply(str)\r\n",
    "data['holiday'] = data['holiday'].apply(str)\r\n",
    "data['Weekend'] = data['Weekend'].apply(str)\r\n",
    "\r\n",
    "data.to_csv(\"test.csv\", mode='w')\r\n",
    "\r\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bag = [\n",
    "    data.loc[data[\"energy_group\"] == \"1\"].copy(),\n",
    "    data.loc[data[\"energy_group\"] == \"2\"].copy(),\n",
    "    data.loc[data[\"energy_group\"] == \"3\"].copy(),\n",
    "    data.loc[data[\"energy_group\"] == \"4\"].copy(),\n",
    "    data.loc[data[\"energy_group\"] == \"5\"].copy()\n",
    "]\n",
    "\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 296   \n",
      "3  | prescalers                         | ModuleDict                      | 208   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.1 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 16.1 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 14.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 33.3 K\n",
      "12 | lstm_decoder                       | LSTM                            | 33.3 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 455   \n",
      "----------------------------------------------------------------------------------------\n",
      "246 K     Trainable params\n",
      "0         Non-trainable params\n",
      "246 K     Total params\n",
      "0.988     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 31/31 [00:07<00:00,  4.16it/s, loss=29.6, v_num=0, val_loss=156.0, train_loss_step=23.00, train_loss_epoch=29.30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 392   \n",
      "3  | prescalers                         | ModuleDict                      | 208   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.1 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 16.1 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 14.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 33.3 K\n",
      "12 | lstm_decoder                       | LSTM                            | 33.3 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 455   \n",
      "----------------------------------------------------------------------------------------\n",
      "247 K     Trainable params\n",
      "0         Non-trainable params\n",
      "247 K     Total params\n",
      "0.988     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 31/31 [00:07<00:00,  4.21it/s, loss=23, v_num=1, val_loss=33.10, train_loss_step=27.70, train_loss_epoch=22.90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 280   \n",
      "3  | prescalers                         | ModuleDict                      | 208   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.1 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 16.1 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 14.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 33.3 K\n",
      "12 | lstm_decoder                       | LSTM                            | 33.3 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 455   \n",
      "----------------------------------------------------------------------------------------\n",
      "246 K     Trainable params\n",
      "0         Non-trainable params\n",
      "246 K     Total params\n",
      "0.988     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 31/31 [00:07<00:00,  4.13it/s, loss=4.56, v_num=2, val_loss=7.950, train_loss_step=3.880, train_loss_epoch=4.600]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 361   \n",
      "3  | prescalers                         | ModuleDict                      | 208   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.1 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 16.1 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 14.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 33.3 K\n",
      "12 | lstm_decoder                       | LSTM                            | 33.3 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 455   \n",
      "----------------------------------------------------------------------------------------\n",
      "247 K     Trainable params\n",
      "0         Non-trainable params\n",
      "247 K     Total params\n",
      "0.988     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 31/31 [00:07<00:00,  3.96it/s, loss=23.5, v_num=3, val_loss=26.10, train_loss_step=23.20, train_loss_epoch=23.10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 354   \n",
      "3  | prescalers                         | ModuleDict                      | 208   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.1 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 16.1 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 14.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 33.3 K\n",
      "12 | lstm_decoder                       | LSTM                            | 33.3 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 455   \n",
      "----------------------------------------------------------------------------------------\n",
      "247 K     Trainable params\n",
      "0         Non-trainable params\n",
      "247 K     Total params\n",
      "0.988     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 31/31 [00:07<00:00,  3.97it/s, loss=20.2, v_num=4, val_loss=38.30, train_loss_step=17.60, train_loss_epoch=20.40]\n"
     ]
    }
   ],
   "source": [
    "for data in data_bag:\r\n",
    "    torch.cuda.empty_cache()\r\n",
    "\r\n",
    "    max_prediction_length = 24\r\n",
    "    max_encoder_length = 168\r\n",
    "    training_cutoff = data[\"time_idx\"].max() - max_prediction_length\r\n",
    "\r\n",
    "    training = TimeSeriesDataSet(\r\n",
    "        data[lambda x: x.time_idx <= training_cutoff],\r\n",
    "        time_idx=\"time_idx\",\r\n",
    "        target=\"kWH\",\r\n",
    "        group_ids=[\"num\"],\r\n",
    "        min_encoder_length=max_encoder_length//2,\r\n",
    "        max_encoder_length=max_encoder_length,\r\n",
    "        min_prediction_length=3,\r\n",
    "        max_prediction_length=max_prediction_length,\r\n",
    "        static_categoricals=[\"num\", \"energy_group\"],\r\n",
    "        static_reals=[\"non_electric_aircondition\", \"sunlight\"],\r\n",
    "        time_varying_known_categoricals=[\"Week\", \"24Hour\", \"holiday\", \"Weekend\"],\r\n",
    "        time_varying_known_reals=[\"C\", \"m/s\", \"wet\", \"mm\", \"hr\", \"time_idx\"],\r\n",
    "        time_varying_unknown_categoricals=[],\r\n",
    "        time_varying_unknown_reals=[\"kWH\"],\r\n",
    "        add_relative_time_idx=True,\r\n",
    "        add_target_scales=True,\r\n",
    "        add_encoder_length=True,\r\n",
    "    )\r\n",
    "\r\n",
    "    # create validation set (predict=True) which means to predict the last max_prediction_length points in time\r\n",
    "    # for each series\r\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\r\n",
    "\r\n",
    "    # create dataloaders for model\r\n",
    "    batch_size = 64  # set this between 32 to 128\r\n",
    "    train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\r\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\r\n",
    "\r\n",
    "    # configure network and trainer\r\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=30, verbose=False, mode=\"min\")\r\n",
    "    lr_logger = LearningRateMonitor()  # log the learning rate\r\n",
    "    logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\r\n",
    "\r\n",
    "    trainer = pl.Trainer(\r\n",
    "        max_epochs=500,\r\n",
    "        gpus=1,\r\n",
    "        weights_summary=\"top\",\r\n",
    "        gradient_clip_val=0.14,\r\n",
    "        limit_train_batches=30, \r\n",
    "        callbacks=[lr_logger, early_stop_callback],\r\n",
    "        logger=logger,\r\n",
    "    )\r\n",
    "\r\n",
    "\r\n",
    "    tft = TemporalFusionTransformer.from_dataset(\r\n",
    "        training,\r\n",
    "        learning_rate=0.03,\r\n",
    "        hidden_size=64,\r\n",
    "        attention_head_size=4,\r\n",
    "        dropout=0.15,\r\n",
    "        hidden_continuous_size=8,\r\n",
    "        output_size=7,\r\n",
    "        loss=QuantileLoss(),\r\n",
    "        log_interval=0,\r\n",
    "        reduce_on_plateau_patience=4,\r\n",
    "    )\r\n",
    "\r\n",
    "    # fit network\r\n",
    "    trainer.fit(\r\n",
    "        tft,\r\n",
    "        train_dataloader=train_dataloader,\r\n",
    "        val_dataloaders=val_dataloader,\r\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('torch1': conda)",
   "name": "python391jvsc74a57bd09ee895ac7264b310fb03733290b11d92306edd4984799744195df454d0c7e440"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}