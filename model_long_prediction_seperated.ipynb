{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd02625b230b0936c03a7a859dabe4a10a429313c958b60e79e367b6eadd1f82f0b",
   "display_name": "Python 3.9.1 64-bit ('torch1': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [\"Save_File/experiment/591.ckpt\"\n",
    ",\"Save_File/experiment/592.ckpt\"\n",
    "]\n",
    "\n",
    "data_paths = [\"Refined_Data/Seperated_Data/59.csv\",\n",
    "\"Refined_Data/Seperated_Data/59.csv\"]\n",
    "\n",
    "# model_paths = [\"Save_File/Group_A_seperated_quantileloss_2lstm_06_01/34.ckpt\"]\n",
    "\n",
    "# data_paths = [\"Refined_Data/Seperated_Data/34.csv\"]\n",
    "\n",
    "# model_paths = [\"Save_File/Group_A_seperated_quantileloss_06_01/4.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_06_01/10.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_06_01/11.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_06_01/12.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_06_01/34.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_06_01/40.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_06_01/41.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_2lstm_06_01/423.ckpt\"]\n",
    "\n",
    "# model_paths = [\"Save_File/Group_A_seperated_quantileloss_2lstm_06_01/4.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_2lstm_06_01/10.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_2lstm_06_01/11.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_2lstm_06_01/12.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_2lstm_06_01/34.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_2lstm_06_01/40.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_2lstm_06_01/41.ckpt\",\n",
    "# \"Save_File/Group_A_seperated_quantileloss_2lstm_06_01/42.ckpt\"]\n",
    "\n",
    "# data_paths = [\"Refined_Data/Seperated_Data/4.csv\",\n",
    "# \"Refined_Data/Seperated_Data/10.csv\",\n",
    "# \"Refined_Data/Seperated_Data/11.csv\",\n",
    "# \"Refined_Data/Seperated_Data/12.csv\",\n",
    "# \"Refined_Data/Seperated_Data/34.csv\",\n",
    "# \"Refined_Data/Seperated_Data/40.csv\",\n",
    "# \"Refined_Data/Seperated_Data/41.csv\",\n",
    "# \"Refined_Data/Seperated_Data/42.csv\"]\n",
    "\n",
    "input_length = 168\n",
    "output_length = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_choice = random.randrange(2,13)\n",
    "\n",
    "# start_point = -168 * random_choice - 1\n",
    "# duration = 168\n",
    "\n",
    "show_graph = False\n",
    "\n",
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "now : Save_File/experiment/591.ckpt, sMAPE score : 8.439735731506183\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 8.171098488365267\n",
      "now step : 2, sMAPE score : 8.305417109935725\n",
      "now : Save_File/experiment/591.ckpt, sMAPE score : 8.644146911749806\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 10.09481994129006\n",
      "now step : 3, sMAPE score : 9.369483426519933\n",
      "now : Save_File/experiment/591.ckpt, sMAPE score : 7.891520149288526\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 9.667703001401659\n",
      "now step : 4, sMAPE score : 8.779611575345093\n",
      "now : Save_File/experiment/591.ckpt, sMAPE score : 9.121571980072684\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 10.887224830831991\n",
      "now step : 5, sMAPE score : 10.004398405452338\n",
      "now : Save_File/experiment/591.ckpt, sMAPE score : 10.314042830428882\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 11.630289260351228\n",
      "now step : 6, sMAPE score : 10.972166045390054\n",
      "now : Save_File/experiment/591.ckpt, sMAPE score : 9.935592003322483\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 11.192360093481746\n",
      "now step : 7, sMAPE score : 10.563976048402115\n",
      "now : Save_File/experiment/591.ckpt, sMAPE score : 9.097647478751492\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 9.79593770482258\n",
      "now step : 8, sMAPE score : 9.446792591787036\n",
      "now : Save_File/experiment/591.ckpt, sMAPE score : 9.06878426630702\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 9.311531482549654\n",
      "now step : 9, sMAPE score : 9.190157874428337\n",
      "now : Save_File/experiment/591.ckpt, sMAPE score : 10.540000986487405\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 10.811160474624682\n",
      "now step : 10, sMAPE score : 10.675580730556042\n",
      "now : Save_File/experiment/591.ckpt, sMAPE score : 10.56095246985069\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 11.125967939553435\n",
      "now step : 11, sMAPE score : 10.843460204702062\n",
      "now : Save_File/experiment/591.ckpt, sMAPE score : 10.660318345250042\n",
      "now : Save_File/experiment/592.ckpt, sMAPE score : 10.806669341004824\n",
      "now step : 12, sMAPE score : 10.733493843127434\n"
     ]
    }
   ],
   "source": [
    "all_smape = []\n",
    "\n",
    "for choice in [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "\n",
    "    step_all_smape = []\n",
    "\n",
    "    start_point = -168 * choice - 1\n",
    "    duration = 168\n",
    "\n",
    "    for i in range(len(model_paths)):\n",
    "        now_dataframe = pd.read_csv(data_paths[i], index_col=0)[start_point:start_point+input_length+duration]\n",
    "        now_dataframe['num'] = now_dataframe['num'].apply(str)\n",
    "        now_dataframe['Week'] = now_dataframe['Week'].apply(str)\n",
    "        now_dataframe['24Hour'] = now_dataframe['24Hour'].apply(str)\n",
    "        now_dataframe['holiday'] = now_dataframe['holiday'].apply(str)\n",
    "        now_dataframe['Weekend'] = now_dataframe['Weekend'].apply(str)\n",
    "        \n",
    "        now_best_tft = TemporalFusionTransformer.load_from_checkpoint(model_paths[i])\n",
    "\n",
    "        original = now_dataframe.iloc[0:input_length+output_length][\"kWH\"].tolist()\n",
    "        prediction = now_dataframe.iloc[0:input_length+output_length][\"kWH\"].tolist()\n",
    "\n",
    "        total_cycle = (len(now_dataframe) - input_length - output_length) // output_length\n",
    "\n",
    "        for k in range(total_cycle):\n",
    "            now_start_point = k*output_length\n",
    "\n",
    "            encoder_data = now_dataframe.iloc[now_start_point:now_start_point+input_length].copy()\n",
    "            decoder_data = now_dataframe.iloc[now_start_point+input_length:now_start_point+input_length+output_length].copy()\n",
    "            new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)\n",
    "\n",
    "            # get prediction, original data\n",
    "            raw_predictions= now_best_tft.predict(new_prediction_data, mode=\"prediction\").numpy().tolist()[0]\n",
    "            originals = now_dataframe.iloc[now_start_point+input_length : now_start_point+input_length+output_length][\"kWH\"].tolist()\n",
    "\n",
    "            prediction.extend(raw_predictions)\n",
    "            original.extend(originals)\n",
    "\n",
    "            # for next step, change dataframe's original value to predicted value\n",
    "            for p in range(output_length):\n",
    "                now_dataframe.iloc[now_start_point+input_length+p, now_dataframe.columns.get_loc(\"kWH\")] = raw_predictions[p]\n",
    "\n",
    "        if show_graph:            \n",
    "            plt.rcParams[\"figure.figsize\"] = (27,7)\n",
    "            fig = plt.figure()\n",
    "            graph = fig.add_subplot(1, 1, 1)\n",
    "            graph.plot(original, color='red')\n",
    "            graph.plot(prediction, color='blue')\n",
    "            plt.show()\n",
    "        \n",
    "        smape_loss = smape(np.array(prediction[168:]), np.array(original[168:]))\n",
    "        all_smape.append(smape_loss)\n",
    "        step_all_smape.append(smape_loss)\n",
    "        print(f\"now : {model_paths[i]}, sMAPE score : {smape_loss}\")\n",
    "\n",
    "    print(f\"now step : {choice}, sMAPE score : {np.mean(np.array(step_all_smape))}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.898594350513289\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.array(all_smape)))"
   ]
  }
 ]
}