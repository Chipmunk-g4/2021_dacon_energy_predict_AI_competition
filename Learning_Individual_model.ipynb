{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "\r\n",
    "import pytorch_lightning as pl\r\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\r\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\r\n",
    "\r\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\r\n",
    "from pytorch_forecasting.data import GroupNormalizer\r\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\r\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./Refined_Data/Grouped_Data/Input_Data2.csv\"\r\n",
    "\r\n",
    "building_num = [[34]]\r\n",
    "\r\n",
    "repeat = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path, parse_dates = [\"date_time\"])\r\n",
    "\r\n",
    "data['num']     =   data['num'].apply(str)\r\n",
    "data['day_of_Week']     =   data['day_of_Week'].apply(str)\r\n",
    "data['day_of_month']    =   data['day_of_month'].apply(str)\r\n",
    "data['24Hour']  =   data['24Hour'].apply(str)\r\n",
    "data['holiday'] =   data['holiday'].apply(str)\r\n",
    "data['Weekend'] =   data['Weekend'].apply(str)\r\n",
    "data['energy_group'] = data['energy_group'].apply(str)\r\n",
    "data['hour_cat']=   data['hour_cat'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bag = [data.loc[data[\"num\"] == str(building_num[i])].copy() for i in range(len(building_num))]\n",
    "\n",
    "data_bag = []\n",
    "for buildings in building_num:\n",
    "    temp = data.loc[data[\"num\"] == str(buildings[0])].copy()\n",
    "    for num_idx in range(1, len(buildings)):\n",
    "        temp = pd.concat([temp, data.loc[data[\"num\"] == str(buildings[num_idx])].copy()])\n",
    "    data_bag.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 618   \n",
      "3  | prescalers                         | ModuleDict                      | 272   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.0 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 25.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 23.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "331 K     Trainable params\n",
      "0         Non-trainable params\n",
      "331 K     Total params\n",
      "1.327     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 11/11 [00:06<00:00,  1.62it/s, loss=0.113, v_num=0, val_loss=0.255, train_loss_step=0.116, train_loss_epoch=0.114]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 618   \n",
      "3  | prescalers                         | ModuleDict                      | 272   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.0 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 25.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 23.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "331 K     Trainable params\n",
      "0         Non-trainable params\n",
      "331 K     Total params\n",
      "1.327     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 11/11 [00:06<00:00,  1.64it/s, loss=0.0928, v_num=1, val_loss=0.218, train_loss_step=0.0943, train_loss_epoch=0.0927]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 618   \n",
      "3  | prescalers                         | ModuleDict                      | 272   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.0 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 25.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 23.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "331 K     Trainable params\n",
      "0         Non-trainable params\n",
      "331 K     Total params\n",
      "1.327     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 11/11 [00:06<00:00,  1.69it/s, loss=0.137, v_num=2, val_loss=0.230, train_loss_step=0.130, train_loss_epoch=0.136]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 618   \n",
      "3  | prescalers                         | ModuleDict                      | 272   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.0 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 25.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 23.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "331 K     Trainable params\n",
      "0         Non-trainable params\n",
      "331 K     Total params\n",
      "1.327     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 11/11 [00:06<00:00,  1.62it/s, loss=0.127, v_num=3, val_loss=0.238, train_loss_step=0.132, train_loss_epoch=0.127]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 618   \n",
      "3  | prescalers                         | ModuleDict                      | 272   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.0 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 25.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 23.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "331 K     Trainable params\n",
      "0         Non-trainable params\n",
      "331 K     Total params\n",
      "1.327     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 11/11 [00:06<00:00,  1.64it/s, loss=0.118, v_num=4, val_loss=0.219, train_loss_step=0.118, train_loss_epoch=0.119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 618   \n",
      "3  | prescalers                         | ModuleDict                      | 272   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.0 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 25.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 23.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "331 K     Trainable params\n",
      "0         Non-trainable params\n",
      "331 K     Total params\n",
      "1.327     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 11/11 [00:06<00:00,  1.66it/s, loss=0.12, v_num=5, val_loss=0.236, train_loss_step=0.117, train_loss_epoch=0.119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 618   \n",
      "3  | prescalers                         | ModuleDict                      | 272   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.0 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 25.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 23.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "331 K     Trainable params\n",
      "0         Non-trainable params\n",
      "331 K     Total params\n",
      "1.327     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 11/11 [00:06<00:00,  1.63it/s, loss=0.116, v_num=6, val_loss=0.238, train_loss_step=0.117, train_loss_epoch=0.115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 618   \n",
      "3  | prescalers                         | ModuleDict                      | 272   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.0 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 25.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 23.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "331 K     Trainable params\n",
      "0         Non-trainable params\n",
      "331 K     Total params\n",
      "1.327     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 11/11 [00:06<00:00,  1.66it/s, loss=0.133, v_num=7, val_loss=0.238, train_loss_step=0.135, train_loss_epoch=0.133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 618   \n",
      "3  | prescalers                         | ModuleDict                      | 272   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.0 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 25.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 23.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "331 K     Trainable params\n",
      "0         Non-trainable params\n",
      "331 K     Total params\n",
      "1.327     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 11/11 [00:06<00:00,  1.68it/s, loss=0.107, v_num=8, val_loss=0.269, train_loss_step=0.112, train_loss_epoch=0.107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 618   \n",
      "3  | prescalers                         | ModuleDict                      | 272   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.0 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 25.3 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 23.2 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 66.6 K\n",
      "12 | lstm_decoder                       | LSTM                            | 66.6 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "331 K     Trainable params\n",
      "0         Non-trainable params\n",
      "331 K     Total params\n",
      "1.327     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eunchan\\anaconda3\\envs\\torch1\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 11/11 [00:06<00:00,  1.67it/s, loss=0.115, v_num=9, val_loss=0.250, train_loss_step=0.113, train_loss_epoch=0.114]\n"
     ]
    }
   ],
   "source": [
    "for ___ in range(repeat):\r\n",
    "    for idx in range(len(data_bag)):\r\n",
    "\r\n",
    "        data = data_bag[idx]\r\n",
    "\r\n",
    "        torch.cuda.empty_cache()\r\n",
    "\r\n",
    "        max_prediction_length = 168\r\n",
    "        max_encoder_length = 336\r\n",
    "        training_cutoff = data[\"time_idx\"].max() - max_prediction_length\r\n",
    "\r\n",
    "        training = TimeSeriesDataSet(\r\n",
    "            data[lambda x: x.time_idx <= training_cutoff],\r\n",
    "            time_idx=\"time_idx\",\r\n",
    "            target=\"kWH\",\r\n",
    "            group_ids=[\"num\"],\r\n",
    "            min_encoder_length=max_encoder_length,\r\n",
    "            max_encoder_length=max_encoder_length,\r\n",
    "            min_prediction_length=max_prediction_length,\r\n",
    "            max_prediction_length=max_prediction_length,\r\n",
    "            static_categoricals=[\"num\", \"energy_group\"],\r\n",
    "            static_reals=[\"non_electric_aircondition\", \"sunlight\"],\r\n",
    "            time_varying_known_categoricals=[\"day_of_Week\", \"day_of_month\", \"24Hour\", \"holiday\", \"Weekend\", \"hour_cat\"],\r\n",
    "            time_varying_known_reals=[\"C\", \"m/s\", \"wet\", \"mm\", \"hr\", \"time_idx\", \"day\", \"Week\", \"perceived_temperature\", \"discomfort_index\"],\r\n",
    "            time_varying_unknown_categoricals=[],\r\n",
    "            time_varying_unknown_reals=[\"kWH\"],\r\n",
    "            add_relative_time_idx=True,\r\n",
    "            add_target_scales=True,\r\n",
    "            add_encoder_length=True\r\n",
    "        )\r\n",
    "\r\n",
    "        # create validation set (predict=True) which means to predict the last max_prediction_length points in time\r\n",
    "        # for each series\r\n",
    "        validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\r\n",
    "\r\n",
    "        # create dataloaders for model\r\n",
    "        batch_size = 64  # set this between 32 to 128\r\n",
    "        train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\r\n",
    "        val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\r\n",
    "\r\n",
    "        # configure network and trainer\r\n",
    "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=20, verbose=False, mode=\"min\")\r\n",
    "        lr_logger = LearningRateMonitor()  # log the learning rate\r\n",
    "        logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\r\n",
    "\r\n",
    "        trainer = pl.Trainer(\r\n",
    "            max_epochs=500,\r\n",
    "            gpus=1,\r\n",
    "            weights_summary=\"top\",\r\n",
    "            gradient_clip_val=0.14,\r\n",
    "            limit_train_batches=10, \r\n",
    "            callbacks=[lr_logger, early_stop_callback],\r\n",
    "            logger=logger,\r\n",
    "        )\r\n",
    "\r\n",
    "\r\n",
    "        tft = TemporalFusionTransformer.from_dataset(\r\n",
    "            training,\r\n",
    "            learning_rate=0.03,\r\n",
    "            hidden_size=64,\r\n",
    "            lstm_layers = 2,\r\n",
    "            attention_head_size=4,\r\n",
    "            dropout=0.15,\r\n",
    "            hidden_continuous_size=8,\r\n",
    "            output_size=1,\r\n",
    "            loss=SMAPE(),\r\n",
    "            log_interval=0,\r\n",
    "            reduce_on_plateau_patience=4,\r\n",
    "        )\r\n",
    "\r\n",
    "        # fit network\r\n",
    "        trainer.fit(\r\n",
    "            tft,\r\n",
    "            train_dataloader=train_dataloader,\r\n",
    "            val_dataloaders=val_dataloader,\r\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('torch1': conda)",
   "name": "python391jvsc74a57bd09ee895ac7264b310fb03733290b11d92306edd4984799744195df454d0c7e440"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}