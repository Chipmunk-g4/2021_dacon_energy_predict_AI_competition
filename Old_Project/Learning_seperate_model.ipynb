{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/train.csv\"\n",
    "\n",
    "group = [\n",
    "    [34, 40, 42, 41, 4, 10, 11, 12],\n",
    "    [35, 6, 48, 27, 57, 8, 25, 56, 26, 55, 47, 13, 53, 18, 7, 17, 46],\n",
    "    [31, 33, 9, 3, 1, 32],\n",
    "    [29, 38, 43, 58, 15, 22, 39, 54, 23, 44, 45, 37, 52, 2, 14],\n",
    "    [21, 19, 50, 49, 20, 51, 30, 36, 28, 59, 5, 60, 16, 24]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  num           date_time       kWH     C  m/s   wet   mm   hr  \\\n",
       "0   1 2020-06-01 00:00:00  8179.056  17.6  2.5  92.0  0.8  0.0   \n",
       "1   1 2020-06-01 01:00:00  8135.640  17.7  2.9  91.0  0.3  0.0   \n",
       "2   1 2020-06-01 02:00:00  8107.128  17.5  3.2  91.0  0.0  0.0   \n",
       "3   1 2020-06-01 03:00:00  8048.808  17.1  3.2  91.0  0.0  0.0   \n",
       "4   1 2020-06-01 04:00:00  8043.624  17.0  3.3  92.0  0.0  0.0   \n",
       "\n",
       "   non_electric_aircondition  sunlight  time_idx energy_group Week 24Hour  \\\n",
       "0                          0         0         0            3    1      0   \n",
       "1                          0         0         1            3    1      1   \n",
       "2                          0         0         2            3    1      2   \n",
       "3                          0         0         3            3    1      3   \n",
       "4                          0         0         4            3    1      4   \n",
       "\n",
       "  holiday Weekend  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num</th>\n      <th>date_time</th>\n      <th>kWH</th>\n      <th>C</th>\n      <th>m/s</th>\n      <th>wet</th>\n      <th>mm</th>\n      <th>hr</th>\n      <th>non_electric_aircondition</th>\n      <th>sunlight</th>\n      <th>time_idx</th>\n      <th>energy_group</th>\n      <th>Week</th>\n      <th>24Hour</th>\n      <th>holiday</th>\n      <th>Weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2020-06-01 00:00:00</td>\n      <td>8179.056</td>\n      <td>17.6</td>\n      <td>2.5</td>\n      <td>92.0</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-06-01 01:00:00</td>\n      <td>8135.640</td>\n      <td>17.7</td>\n      <td>2.9</td>\n      <td>91.0</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2020-06-01 02:00:00</td>\n      <td>8107.128</td>\n      <td>17.5</td>\n      <td>3.2</td>\n      <td>91.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2020-06-01 03:00:00</td>\n      <td>8048.808</td>\n      <td>17.1</td>\n      <td>3.2</td>\n      <td>91.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2020-06-01 04:00:00</td>\n      <td>8043.624</td>\n      <td>17.0</td>\n      <td>3.3</td>\n      <td>92.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data = pd.read_csv(data_path, parse_dates = [\"date_time\"])\r\n",
    "\r\n",
    "data[\"time_idx\"] = 0\r\n",
    "data[\"month\"] = 0\r\n",
    "data[\"energy_group\"] = 0\r\n",
    "data[\"Week\"] = 0\r\n",
    "data[\"24Hour\"] = 0\r\n",
    "data[\"holiday\"] = 0\r\n",
    "data[\"Weekend\"] = 0\r\n",
    "\r\n",
    "data.loc[data[\"num\"].isin(group[0]), \"energy_group\"] = str(1)\r\n",
    "data.loc[data[\"num\"].isin(group[1]), \"energy_group\"] = str(2)\r\n",
    "data.loc[data[\"num\"].isin(group[2]), \"energy_group\"] = str(3)\r\n",
    "data.loc[data[\"num\"].isin(group[3]), \"energy_group\"] = str(4)\r\n",
    "data.loc[data[\"num\"].isin(group[4]), \"energy_group\"] = str(5)\r\n",
    "\r\n",
    "data.loc[data[\"date_time\"].dt.month == 6, 'month'] = 0\r\n",
    "data.loc[data[\"date_time\"].dt.month == 7, 'month'] = 30\r\n",
    "data.loc[data[\"date_time\"].dt.month == 8, 'month'] = 61\r\n",
    "\r\n",
    "data.loc[(data[\"date_time\"].dt.month == 8) & (data[\"date_time\"].dt.day == 17) , 'holiday'] = 1\r\n",
    "\r\n",
    "data[\"time_idx\"] = data[\"date_time\"].dt.hour + data[\"date_time\"].dt.day * (24) + data[\"month\"] * 24\r\n",
    "data[\"time_idx\"] = data[\"time_idx\"] - min(data[\"time_idx\"])\r\n",
    "\r\n",
    "data[\"Week\"] = (data[\"date_time\"].dt.day + data[\"month\"]) % 7\r\n",
    "data[\"24Hour\"] = data[\"date_time\"].dt.hour\r\n",
    "\r\n",
    "data.loc[data[\"Week\"] == 6, 'Weekend'] = 1\r\n",
    "data.loc[data[\"Week\"] == 0, 'Weekend'] = 1\r\n",
    "\r\n",
    "data = data.drop(\"month\",axis='columns')\r\n",
    "\r\n",
    "data.rename(columns = {'전력사용량(kWh)' : 'kWH', '기온(°C)' : 'C', '풍속(m/s)' : 'm/s', '습도(%)' : 'wet', '강수량(mm)' : 'mm','일조(hr)' : 'hr', '비전기냉방설비운영' : \"non_electric_aircondition\", \"태양광보유\" : \"sunlight\"}, inplace = True)\r\n",
    "\r\n",
    "data = data.astype({'non_electric_aircondition' : int, 'sunlight' : int})\r\n",
    "data['num'] = data['num'].apply(str)\r\n",
    "data['Week'] = data['Week'].apply(str)\r\n",
    "data['24Hour'] = data['24Hour'].apply(str)\r\n",
    "data['holiday'] = data['holiday'].apply(str)\r\n",
    "data['Weekend'] = data['Weekend'].apply(str)\r\n",
    "\r\n",
    "data.to_csv(\"test.csv\", mode='w')\r\n",
    "\r\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bag = [\n",
    "    data.loc[data[\"energy_group\"] == \"1\"].copy(),\n",
    "    data.loc[data[\"energy_group\"] == \"2\"].copy(),\n",
    "    data.loc[data[\"energy_group\"] == \"3\"].copy(),\n",
    "    data.loc[data[\"energy_group\"] == \"4\"].copy(),\n",
    "    data.loc[data[\"energy_group\"] == \"5\"].copy()\n",
    "]\n",
    "\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65: 100%|██████████| 31/31 [00:07<00:00,  4.40it/s, loss=27.2, v_num=3, val_loss=27.30, train_loss_step=28.80, train_loss_epoch=27.20]\n",
      "Epoch 66:  97%|█████████▋| 30/31 [00:07<00:00,  4.17it/s, loss=26.9, v_num=3, val_loss=27.30, train_loss_step=26.90, train_loss_epoch=27.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66: 100%|██████████| 31/31 [00:07<00:00,  4.26it/s, loss=26.9, v_num=3, val_loss=27.30, train_loss_step=31.90, train_loss_epoch=26.60]\n",
      "Epoch 67:  97%|█████████▋| 30/31 [00:07<00:00,  3.99it/s, loss=26.6, v_num=3, val_loss=27.30, train_loss_step=24.80, train_loss_epoch=26.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67: 100%|██████████| 31/31 [00:07<00:00,  4.07it/s, loss=26.6, v_num=3, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=26.60]\n",
      "Epoch 68:  97%|█████████▋| 30/31 [00:06<00:00,  4.31it/s, loss=27.1, v_num=3, val_loss=27.30, train_loss_step=24.40, train_loss_epoch=26.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68: 100%|██████████| 31/31 [00:07<00:00,  4.39it/s, loss=27.1, v_num=3, val_loss=27.30, train_loss_step=29.70, train_loss_epoch=26.90]\n",
      "Epoch 68: 100%|██████████| 31/31 [00:07<00:00,  4.39it/s, loss=27.1, v_num=3, val_loss=27.30, train_loss_step=29.70, train_loss_epoch=26.90]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 354   \n",
      "3  | prescalers                         | ModuleDict                      | 208   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.3 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 6.1 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 5.3 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 4.4 K \n",
      "12 | lstm_decoder                       | LSTM                            | 4.4 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 676   \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "33.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.2 K    Total params\n",
      "0.133     Total estimated model params size (MB)\n",
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]/home/joeunchan/anaconda3/envs/torch1/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s] /home/joeunchan/anaconda3/envs/torch1/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  97%|█████████▋| 30/31 [00:07<00:00,  4.14it/s, loss=105, v_num=4, val_loss=233.0, train_loss_step=86.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 31/31 [00:07<00:00,  4.23it/s, loss=105, v_num=4, val_loss=111.0, train_loss_step=100.0, train_loss_epoch=123.0]\n",
      "Epoch 1:  97%|█████████▋| 30/31 [00:07<00:00,  4.12it/s, loss=75.2, v_num=4, val_loss=111.0, train_loss_step=73.90, train_loss_epoch=123.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 31/31 [00:07<00:00,  4.19it/s, loss=75.2, v_num=4, val_loss=82.40, train_loss_step=64.30, train_loss_epoch=76.20]\n",
      "Epoch 2:  97%|█████████▋| 30/31 [00:07<00:00,  4.21it/s, loss=65.7, v_num=4, val_loss=82.40, train_loss_step=61.10, train_loss_epoch=76.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 31/31 [00:07<00:00,  4.30it/s, loss=65.7, v_num=4, val_loss=68.30, train_loss_step=62.40, train_loss_epoch=66.90]\n",
      "Epoch 3:  97%|█████████▋| 30/31 [00:07<00:00,  4.01it/s, loss=59.5, v_num=4, val_loss=68.30, train_loss_step=58.40, train_loss_epoch=66.90]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 31/31 [00:07<00:00,  4.09it/s, loss=59.5, v_num=4, val_loss=58.00, train_loss_step=66.30, train_loss_epoch=59.90]\n",
      "Epoch 4:  97%|█████████▋| 30/31 [00:07<00:00,  3.99it/s, loss=56.8, v_num=4, val_loss=58.00, train_loss_step=52.80, train_loss_epoch=59.90]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 31/31 [00:07<00:00,  4.08it/s, loss=56.8, v_num=4, val_loss=54.10, train_loss_step=52.70, train_loss_epoch=57.10]\n",
      "Epoch 5:  97%|█████████▋| 30/31 [00:07<00:00,  4.11it/s, loss=50.7, v_num=4, val_loss=54.10, train_loss_step=52.90, train_loss_epoch=57.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 31/31 [00:07<00:00,  4.20it/s, loss=50.7, v_num=4, val_loss=48.90, train_loss_step=49.90, train_loss_epoch=51.00]\n",
      "Epoch 6:  97%|█████████▋| 30/31 [00:07<00:00,  4.18it/s, loss=47.5, v_num=4, val_loss=48.90, train_loss_step=50.60, train_loss_epoch=51.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 31/31 [00:07<00:00,  4.26it/s, loss=47.5, v_num=4, val_loss=45.80, train_loss_step=54.60, train_loss_epoch=48.90]\n",
      "Epoch 7:  97%|█████████▋| 30/31 [00:07<00:00,  4.15it/s, loss=42.3, v_num=4, val_loss=45.80, train_loss_step=40.20, train_loss_epoch=48.90]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 31/31 [00:07<00:00,  4.23it/s, loss=42.3, v_num=4, val_loss=42.80, train_loss_step=45.80, train_loss_epoch=43.70]\n",
      "Epoch 8:  97%|█████████▋| 30/31 [00:07<00:00,  4.02it/s, loss=40.4, v_num=4, val_loss=42.80, train_loss_step=39.60, train_loss_epoch=43.70]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 31/31 [00:07<00:00,  4.11it/s, loss=40.4, v_num=4, val_loss=40.40, train_loss_step=50.50, train_loss_epoch=40.80]\n",
      "Epoch 9:  97%|█████████▋| 30/31 [00:07<00:00,  4.09it/s, loss=38.7, v_num=4, val_loss=40.40, train_loss_step=46.50, train_loss_epoch=40.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 31/31 [00:07<00:00,  4.18it/s, loss=38.7, v_num=4, val_loss=38.60, train_loss_step=38.40, train_loss_epoch=40.00]\n",
      "Epoch 10:  97%|█████████▋| 30/31 [00:07<00:00,  4.06it/s, loss=37.9, v_num=4, val_loss=38.60, train_loss_step=39.20, train_loss_epoch=40.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 31/31 [00:07<00:00,  4.16it/s, loss=37.9, v_num=4, val_loss=39.50, train_loss_step=34.20, train_loss_epoch=37.70]\n",
      "Epoch 11:  97%|█████████▋| 30/31 [00:07<00:00,  4.04it/s, loss=36.1, v_num=4, val_loss=39.50, train_loss_step=33.80, train_loss_epoch=37.70]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 31/31 [00:07<00:00,  4.13it/s, loss=36.1, v_num=4, val_loss=44.60, train_loss_step=39.00, train_loss_epoch=36.00]\n",
      "Epoch 12:  97%|█████████▋| 30/31 [00:07<00:00,  4.06it/s, loss=34.8, v_num=4, val_loss=44.60, train_loss_step=38.80, train_loss_epoch=36.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 31/31 [00:07<00:00,  4.14it/s, loss=34.8, v_num=4, val_loss=43.90, train_loss_step=44.60, train_loss_epoch=34.90]\n",
      "Epoch 13:  97%|█████████▋| 30/31 [00:07<00:00,  4.17it/s, loss=32.6, v_num=4, val_loss=43.90, train_loss_step=35.30, train_loss_epoch=34.90]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 31/31 [00:07<00:00,  4.23it/s, loss=32.6, v_num=4, val_loss=51.50, train_loss_step=30.30, train_loss_epoch=33.00]\n",
      "Epoch 14:  97%|█████████▋| 30/31 [00:07<00:00,  4.12it/s, loss=34.4, v_num=4, val_loss=51.50, train_loss_step=43.90, train_loss_epoch=33.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 31/31 [00:07<00:00,  4.21it/s, loss=34.4, v_num=4, val_loss=39.00, train_loss_step=35.50, train_loss_epoch=34.80]\n",
      "Epoch 15:  97%|█████████▋| 30/31 [00:07<00:00,  4.16it/s, loss=31.7, v_num=4, val_loss=39.00, train_loss_step=31.00, train_loss_epoch=34.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 31/31 [00:07<00:00,  4.24it/s, loss=31.7, v_num=4, val_loss=40.60, train_loss_step=29.90, train_loss_epoch=32.20]\n",
      "Epoch 16:  97%|█████████▋| 30/31 [00:07<00:00,  4.18it/s, loss=30.3, v_num=4, val_loss=40.60, train_loss_step=33.70, train_loss_epoch=32.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 31/31 [00:07<00:00,  4.26it/s, loss=30.3, v_num=4, val_loss=41.00, train_loss_step=25.10, train_loss_epoch=30.80]\n",
      "Epoch 17:  97%|█████████▋| 30/31 [00:07<00:00,  4.09it/s, loss=30.3, v_num=4, val_loss=41.00, train_loss_step=26.40, train_loss_epoch=30.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 31/31 [00:07<00:00,  4.18it/s, loss=30.3, v_num=4, val_loss=40.00, train_loss_step=30.10, train_loss_epoch=30.50]\n",
      "Epoch 18:  97%|█████████▋| 30/31 [00:07<00:00,  4.23it/s, loss=31, v_num=4, val_loss=40.00, train_loss_step=24.90, train_loss_epoch=30.50]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 31/31 [00:07<00:00,  4.31it/s, loss=31, v_num=4, val_loss=38.50, train_loss_step=26.90, train_loss_epoch=30.90]\n",
      "Epoch 19:  97%|█████████▋| 30/31 [00:07<00:00,  4.07it/s, loss=29, v_num=4, val_loss=38.50, train_loss_step=25.20, train_loss_epoch=30.90]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 31/31 [00:07<00:00,  4.15it/s, loss=29, v_num=4, val_loss=40.60, train_loss_step=27.60, train_loss_epoch=29.00]\n",
      "Epoch 20:  97%|█████████▋| 30/31 [00:07<00:00,  4.21it/s, loss=30.5, v_num=4, val_loss=40.60, train_loss_step=32.80, train_loss_epoch=29.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 31/31 [00:07<00:00,  4.30it/s, loss=30.5, v_num=4, val_loss=39.70, train_loss_step=26.10, train_loss_epoch=30.30]\n",
      "Epoch 21:  97%|█████████▋| 30/31 [00:07<00:00,  4.21it/s, loss=30, v_num=4, val_loss=39.70, train_loss_step=29.50, train_loss_epoch=30.30]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|██████████| 31/31 [00:07<00:00,  4.31it/s, loss=30, v_num=4, val_loss=40.00, train_loss_step=32.50, train_loss_epoch=29.40]\n",
      "Epoch 22:  97%|█████████▋| 30/31 [00:07<00:00,  4.15it/s, loss=28, v_num=4, val_loss=40.00, train_loss_step=29.90, train_loss_epoch=29.40]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|██████████| 31/31 [00:07<00:00,  4.23it/s, loss=28, v_num=4, val_loss=41.10, train_loss_step=34.10, train_loss_epoch=29.00]\n",
      "Epoch 23:  97%|█████████▋| 30/31 [00:07<00:00,  4.17it/s, loss=28.4, v_num=4, val_loss=41.10, train_loss_step=30.80, train_loss_epoch=29.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|██████████| 31/31 [00:07<00:00,  4.27it/s, loss=28.4, v_num=4, val_loss=38.80, train_loss_step=30.30, train_loss_epoch=28.70]\n",
      "Epoch 24:  97%|█████████▋| 30/31 [00:07<00:00,  4.06it/s, loss=29.5, v_num=4, val_loss=38.80, train_loss_step=26.60, train_loss_epoch=28.70]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|██████████| 31/31 [00:07<00:00,  4.16it/s, loss=29.5, v_num=4, val_loss=38.90, train_loss_step=26.20, train_loss_epoch=29.10]\n",
      "Epoch 25:  97%|█████████▋| 30/31 [00:07<00:00,  4.28it/s, loss=30.1, v_num=4, val_loss=38.90, train_loss_step=36.50, train_loss_epoch=29.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|██████████| 31/31 [00:07<00:00,  4.37it/s, loss=30.1, v_num=4, val_loss=39.40, train_loss_step=23.80, train_loss_epoch=29.70]\n",
      "Epoch 26:  97%|█████████▋| 30/31 [00:07<00:00,  4.12it/s, loss=29.3, v_num=4, val_loss=39.40, train_loss_step=26.50, train_loss_epoch=29.70]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|██████████| 31/31 [00:07<00:00,  4.20it/s, loss=29.3, v_num=4, val_loss=38.60, train_loss_step=28.10, train_loss_epoch=29.20]\n",
      "Epoch 27:  97%|█████████▋| 30/31 [00:07<00:00,  4.26it/s, loss=29.8, v_num=4, val_loss=38.60, train_loss_step=32.70, train_loss_epoch=29.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|██████████| 31/31 [00:07<00:00,  4.36it/s, loss=29.8, v_num=4, val_loss=38.70, train_loss_step=29.50, train_loss_epoch=29.30]\n",
      "Epoch 28:  97%|█████████▋| 30/31 [00:07<00:00,  4.14it/s, loss=29.1, v_num=4, val_loss=38.70, train_loss_step=31.00, train_loss_epoch=29.30]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|██████████| 31/31 [00:07<00:00,  4.23it/s, loss=29.1, v_num=4, val_loss=39.10, train_loss_step=33.00, train_loss_epoch=28.50]\n",
      "Epoch 29:  97%|█████████▋| 30/31 [00:07<00:00,  4.10it/s, loss=28.4, v_num=4, val_loss=39.10, train_loss_step=30.20, train_loss_epoch=28.50]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|██████████| 31/31 [00:07<00:00,  4.19it/s, loss=28.4, v_num=4, val_loss=38.90, train_loss_step=26.30, train_loss_epoch=28.60]\n",
      "Epoch 30:  97%|█████████▋| 30/31 [00:07<00:00,  4.14it/s, loss=29, v_num=4, val_loss=38.90, train_loss_step=26.00, train_loss_epoch=28.60]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|██████████| 31/31 [00:07<00:00,  4.22it/s, loss=29, v_num=4, val_loss=39.60, train_loss_step=27.50, train_loss_epoch=29.10]\n",
      "Epoch 31:  97%|█████████▋| 30/31 [00:07<00:00,  4.09it/s, loss=29.6, v_num=4, val_loss=39.60, train_loss_step=31.00, train_loss_epoch=29.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|██████████| 31/31 [00:07<00:00,  4.16it/s, loss=29.6, v_num=4, val_loss=39.30, train_loss_step=28.20, train_loss_epoch=29.50]\n",
      "Epoch 32:  97%|█████████▋| 30/31 [00:07<00:00,  4.02it/s, loss=28.4, v_num=4, val_loss=39.30, train_loss_step=32.90, train_loss_epoch=29.50]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|██████████| 31/31 [00:07<00:00,  4.10it/s, loss=28.4, v_num=4, val_loss=38.90, train_loss_step=31.70, train_loss_epoch=28.50]\n",
      "Epoch 33:  97%|█████████▋| 30/31 [00:07<00:00,  4.13it/s, loss=28.6, v_num=4, val_loss=38.90, train_loss_step=29.50, train_loss_epoch=28.50]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|██████████| 31/31 [00:07<00:00,  4.22it/s, loss=28.6, v_num=4, val_loss=39.20, train_loss_step=33.00, train_loss_epoch=28.50]\n",
      "Epoch 34:  97%|█████████▋| 30/31 [00:07<00:00,  4.10it/s, loss=28.8, v_num=4, val_loss=39.20, train_loss_step=31.30, train_loss_epoch=28.50]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|██████████| 31/31 [00:07<00:00,  4.18it/s, loss=28.8, v_num=4, val_loss=39.40, train_loss_step=27.70, train_loss_epoch=29.10]\n",
      "Epoch 35:  97%|█████████▋| 30/31 [00:07<00:00,  4.18it/s, loss=28.3, v_num=4, val_loss=39.40, train_loss_step=25.50, train_loss_epoch=29.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|██████████| 31/31 [00:07<00:00,  4.27it/s, loss=28.3, v_num=4, val_loss=39.50, train_loss_step=28.50, train_loss_epoch=28.60]\n",
      "Epoch 36:  97%|█████████▋| 30/31 [00:06<00:00,  4.29it/s, loss=29.2, v_num=4, val_loss=39.50, train_loss_step=27.50, train_loss_epoch=28.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|██████████| 31/31 [00:07<00:00,  4.37it/s, loss=29.2, v_num=4, val_loss=39.70, train_loss_step=31.60, train_loss_epoch=29.30]\n",
      "Epoch 37:  97%|█████████▋| 30/31 [00:07<00:00,  4.18it/s, loss=28.9, v_num=4, val_loss=39.70, train_loss_step=28.70, train_loss_epoch=29.30]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|██████████| 31/31 [00:07<00:00,  4.27it/s, loss=28.9, v_num=4, val_loss=39.60, train_loss_step=29.60, train_loss_epoch=28.90]\n",
      "Epoch 38:  97%|█████████▋| 30/31 [00:07<00:00,  4.19it/s, loss=29.9, v_num=4, val_loss=39.60, train_loss_step=25.90, train_loss_epoch=28.90]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|██████████| 31/31 [00:07<00:00,  4.26it/s, loss=29.9, v_num=4, val_loss=39.40, train_loss_step=34.50, train_loss_epoch=29.80]\n",
      "Epoch 39:  97%|█████████▋| 30/31 [00:07<00:00,  4.09it/s, loss=29.3, v_num=4, val_loss=39.40, train_loss_step=29.10, train_loss_epoch=29.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|██████████| 31/31 [00:07<00:00,  4.17it/s, loss=29.3, v_num=4, val_loss=39.10, train_loss_step=22.20, train_loss_epoch=29.50]\n",
      "Epoch 40:  97%|█████████▋| 30/31 [00:07<00:00,  4.21it/s, loss=29.1, v_num=4, val_loss=39.10, train_loss_step=31.30, train_loss_epoch=29.50]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40: 100%|██████████| 31/31 [00:07<00:00,  4.30it/s, loss=29.1, v_num=4, val_loss=39.00, train_loss_step=35.30, train_loss_epoch=29.50]\n",
      "Epoch 41:  97%|█████████▋| 30/31 [00:07<00:00,  4.21it/s, loss=29.7, v_num=4, val_loss=39.00, train_loss_step=28.40, train_loss_epoch=29.50]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41: 100%|██████████| 31/31 [00:07<00:00,  4.30it/s, loss=29.7, v_num=4, val_loss=39.00, train_loss_step=29.70, train_loss_epoch=29.50]\n",
      "Epoch 42:  97%|█████████▋| 30/31 [00:07<00:00,  4.07it/s, loss=27.9, v_num=4, val_loss=39.00, train_loss_step=26.80, train_loss_epoch=29.50]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42: 100%|██████████| 31/31 [00:07<00:00,  4.14it/s, loss=27.9, v_num=4, val_loss=39.10, train_loss_step=29.70, train_loss_epoch=27.90]\n",
      "Epoch 43:  97%|█████████▋| 30/31 [00:07<00:00,  4.19it/s, loss=28.1, v_num=4, val_loss=39.10, train_loss_step=31.50, train_loss_epoch=27.90]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43: 100%|██████████| 31/31 [00:07<00:00,  4.26it/s, loss=28.1, v_num=4, val_loss=39.20, train_loss_step=28.60, train_loss_epoch=28.30]\n",
      "Epoch 44:  97%|█████████▋| 30/31 [00:07<00:00,  4.27it/s, loss=29.9, v_num=4, val_loss=39.20, train_loss_step=30.50, train_loss_epoch=28.30]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44: 100%|██████████| 31/31 [00:07<00:00,  4.36it/s, loss=29.9, v_num=4, val_loss=39.20, train_loss_step=32.30, train_loss_epoch=29.20]\n",
      "Epoch 45:  97%|█████████▋| 30/31 [00:07<00:00,  4.09it/s, loss=28.7, v_num=4, val_loss=39.20, train_loss_step=26.40, train_loss_epoch=29.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45: 100%|██████████| 31/31 [00:07<00:00,  4.17it/s, loss=28.7, v_num=4, val_loss=39.20, train_loss_step=31.40, train_loss_epoch=28.80]\n",
      "Epoch 46:  97%|█████████▋| 30/31 [00:07<00:00,  4.20it/s, loss=29.4, v_num=4, val_loss=39.20, train_loss_step=33.60, train_loss_epoch=28.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 46: 100%|██████████| 31/31 [00:07<00:00,  4.29it/s, loss=29.4, v_num=4, val_loss=39.20, train_loss_step=28.00, train_loss_epoch=29.20]\n",
      "Epoch 47:  97%|█████████▋| 30/31 [00:07<00:00,  4.17it/s, loss=30.1, v_num=4, val_loss=39.20, train_loss_step=23.20, train_loss_epoch=29.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47: 100%|██████████| 31/31 [00:07<00:00,  4.26it/s, loss=30.1, v_num=4, val_loss=39.20, train_loss_step=36.60, train_loss_epoch=30.30]\n",
      "Epoch 48:  97%|█████████▋| 30/31 [00:07<00:00,  4.18it/s, loss=30, v_num=4, val_loss=39.20, train_loss_step=32.50, train_loss_epoch=30.30]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48: 100%|██████████| 31/31 [00:07<00:00,  4.28it/s, loss=30, v_num=4, val_loss=39.30, train_loss_step=31.10, train_loss_epoch=30.00]\n",
      "Epoch 48: 100%|██████████| 31/31 [00:07<00:00,  4.27it/s, loss=30, v_num=4, val_loss=39.30, train_loss_step=31.10, train_loss_epoch=30.00]\n"
     ]
    }
   ],
   "source": [
    "for data in data_bag:\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    max_prediction_length = 24\n",
    "    max_encoder_length = 168\n",
    "    training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "    training = TimeSeriesDataSet(\n",
    "        data[lambda x: x.time_idx <= training_cutoff],\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"kWH\",\n",
    "        group_ids=[\"num\"],\n",
    "        min_encoder_length=max_encoder_length//2,\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=3,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=[\"num\", \"energy_group\"],\n",
    "        static_reals=[\"non_electric_aircondition\", \"sunlight\"],\n",
    "        time_varying_known_categoricals=[\"Week\", \"24Hour\", \"holiday\", \"Weekend\"],\n",
    "        time_varying_known_reals=[\"C\", \"m/s\", \"wet\", \"mm\", \"hr\", \"time_idx\"],\n",
    "        time_varying_unknown_categoricals=[],\n",
    "        time_varying_unknown_reals=[\"kWH\"],\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "    )\n",
    "\n",
    "    # create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "    # for each series\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "    # create dataloaders for model\n",
    "    batch_size = 64  # set this between 32 to 128\n",
    "    train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "    # configure network and trainer\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=30, verbose=False, mode=\"min\")\n",
    "    lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "    logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=500,\n",
    "        gpus=1,\n",
    "        weights_summary=\"top\",\n",
    "        gradient_clip_val=0.14,\n",
    "        limit_train_batches=30, \n",
    "        callbacks=[lr_logger, early_stop_callback],\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "\n",
    "    tft = TemporalFusionTransformer.from_dataset(\n",
    "        training,\n",
    "        learning_rate=0.03,\n",
    "        hidden_size=16,\n",
    "        lstm_layers = 2,\n",
    "        attention_head_size=4,\n",
    "        dropout=0.15,\n",
    "        hidden_continuous_size=8,\n",
    "        output_size=7,\n",
    "        loss=QuantileLoss(),\n",
    "        log_interval=0,\n",
    "        reduce_on_plateau_patience=4,\n",
    "    )\n",
    "\n",
    "    # fit network\n",
    "    trainer.fit(\n",
    "        tft,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd02625b230b0936c03a7a859dabe4a10a429313c958b60e79e367b6eadd1f82f0b",
   "display_name": "Python 3.9.1 64-bit ('torch1': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}