{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss, MultiHorizonMetric\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./Refined_Data/Grouped_Data/Input_Data2.csv\"\n",
    "\n",
    "group = [\n",
    "    [34, 40, 42, 41, 4, 10, 11, 12],\n",
    "    [35, 6, 48, 27, 57, 8, 25, 56, 26, 55, 47, 13, 53, 18, 7, 17, 46],\n",
    "    [31, 33, 9, 3, 1, 32],\n",
    "    [29, 38, 43, 58, 15, 22, 39, 54, 23, 44, 45, 37, 52, 2, 14],\n",
    "    [21, 19, 50, 49, 20, 51, 30, 36, 28, 59, 5, 60, 16, 24]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path, parse_dates = [\"date_time\"])\n",
    "\n",
    "data['num']     =   data['num'].apply(str)\n",
    "data['day_of_Week']     =   data['day_of_Week'].apply(str)\n",
    "data['day_of_month']    =   data['day_of_month'].apply(str)\n",
    "data['24Hour']  =   data['24Hour'].apply(str)\n",
    "data['holiday'] =   data['holiday'].apply(str)\n",
    "data['Weekend'] =   data['Weekend'].apply(str)\n",
    "data['energy_group'] = data['energy_group'].apply(str)\n",
    "data['hour_cat']=   data['hour_cat'].apply(str)\n",
    "# data['discomfort_index'] = data['discomfort_index'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bag = [data.loc[data[\"energy_group\"] == str(i)].copy() for i in range(len(group))]\r\n",
    "\r\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "m=3, val_loss=0.0563, train_loss_step=0.0273, train_loss_epoch=0.0277]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41: 100%|██████████| 31/31 [00:17<00:00,  1.79it/s, loss=0.0272, v_num=3, val_loss=0.0566, train_loss_step=0.025, train_loss_epoch=0.0273] \n",
      "Epoch 42:  97%|█████████▋| 30/31 [00:16<00:00,  1.81it/s, loss=0.0276, v_num=3, val_loss=0.0566, train_loss_step=0.0295, train_loss_epoch=0.0273]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42: 100%|██████████| 31/31 [00:16<00:00,  1.86it/s, loss=0.0276, v_num=3, val_loss=0.0568, train_loss_step=0.0254, train_loss_epoch=0.0275]\n",
      "Epoch 43:  97%|█████████▋| 30/31 [00:17<00:00,  1.76it/s, loss=0.0274, v_num=3, val_loss=0.0568, train_loss_step=0.0261, train_loss_epoch=0.0275]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43: 100%|██████████| 31/31 [00:17<00:00,  1.80it/s, loss=0.0274, v_num=3, val_loss=0.0562, train_loss_step=0.0263, train_loss_epoch=0.0275]\n",
      "Epoch 44:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.0275, v_num=3, val_loss=0.0562, train_loss_step=0.026, train_loss_epoch=0.0275] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44: 100%|██████████| 31/31 [00:17<00:00,  1.81it/s, loss=0.0275, v_num=3, val_loss=0.0554, train_loss_step=0.0302, train_loss_epoch=0.0274]\n",
      "Epoch 45:  97%|█████████▋| 30/31 [00:16<00:00,  1.80it/s, loss=0.0265, v_num=3, val_loss=0.0554, train_loss_step=0.0269, train_loss_epoch=0.0274]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45: 100%|██████████| 31/31 [00:16<00:00,  1.84it/s, loss=0.0265, v_num=3, val_loss=0.0559, train_loss_step=0.023, train_loss_epoch=0.0268] \n",
      "Epoch 46:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.027, v_num=3, val_loss=0.0559, train_loss_step=0.029, train_loss_epoch=0.0268] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 46: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.027, v_num=3, val_loss=0.056, train_loss_step=0.0271, train_loss_epoch=0.027] \n",
      "Epoch 47:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.0265, v_num=3, val_loss=0.056, train_loss_step=0.0291, train_loss_epoch=0.027]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.0265, v_num=3, val_loss=0.0556, train_loss_step=0.026, train_loss_epoch=0.0265]\n",
      "Epoch 48:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=0.0269, v_num=3, val_loss=0.0556, train_loss_step=0.0296, train_loss_epoch=0.0265]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48: 100%|██████████| 31/31 [00:16<00:00,  1.83it/s, loss=0.0269, v_num=3, val_loss=0.0554, train_loss_step=0.0246, train_loss_epoch=0.0268]\n",
      "Epoch 49:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.0265, v_num=3, val_loss=0.0554, train_loss_step=0.0252, train_loss_epoch=0.0268]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.0265, v_num=3, val_loss=0.0557, train_loss_step=0.0285, train_loss_epoch=0.0266]\n",
      "Epoch 50:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.0263, v_num=3, val_loss=0.0557, train_loss_step=0.0243, train_loss_epoch=0.0266]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 50: 100%|██████████| 31/31 [00:16<00:00,  1.84it/s, loss=0.0263, v_num=3, val_loss=0.0553, train_loss_step=0.0259, train_loss_epoch=0.0264]\n",
      "Epoch 51:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=0.0262, v_num=3, val_loss=0.0553, train_loss_step=0.0275, train_loss_epoch=0.0264]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 51: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.0262, v_num=3, val_loss=0.0553, train_loss_step=0.0243, train_loss_epoch=0.026] \n",
      "Epoch 52:  97%|█████████▋| 30/31 [00:17<00:00,  1.73it/s, loss=0.0259, v_num=3, val_loss=0.0553, train_loss_step=0.0251, train_loss_epoch=0.026]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 52: 100%|██████████| 31/31 [00:17<00:00,  1.78it/s, loss=0.0259, v_num=3, val_loss=0.056, train_loss_step=0.0241, train_loss_epoch=0.0261]\n",
      "Epoch 53:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.0256, v_num=3, val_loss=0.056, train_loss_step=0.0271, train_loss_epoch=0.0261]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 53: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.0256, v_num=3, val_loss=0.0562, train_loss_step=0.0281, train_loss_epoch=0.0257]\n",
      "Epoch 54:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=0.0251, v_num=3, val_loss=0.0562, train_loss_step=0.0254, train_loss_epoch=0.0257]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 54: 100%|██████████| 31/31 [00:16<00:00,  1.83it/s, loss=0.0251, v_num=3, val_loss=0.0559, train_loss_step=0.0254, train_loss_epoch=0.0254]\n",
      "Epoch 55:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=0.0257, v_num=3, val_loss=0.0559, train_loss_step=0.0258, train_loss_epoch=0.0254]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 55: 100%|██████████| 31/31 [00:16<00:00,  1.83it/s, loss=0.0257, v_num=3, val_loss=0.0553, train_loss_step=0.0246, train_loss_epoch=0.0256]\n",
      "Epoch 56:  97%|█████████▋| 30/31 [00:16<00:00,  1.80it/s, loss=0.0253, v_num=3, val_loss=0.0553, train_loss_step=0.0255, train_loss_epoch=0.0256]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 56: 100%|██████████| 31/31 [00:16<00:00,  1.85it/s, loss=0.0253, v_num=3, val_loss=0.0553, train_loss_step=0.0248, train_loss_epoch=0.0255]\n",
      "Epoch 57:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=0.0259, v_num=3, val_loss=0.0553, train_loss_step=0.0278, train_loss_epoch=0.0255]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 57: 100%|██████████| 31/31 [00:16<00:00,  1.82it/s, loss=0.0259, v_num=3, val_loss=0.0552, train_loss_step=0.0264, train_loss_epoch=0.0256]\n",
      "Epoch 58:  97%|█████████▋| 30/31 [00:16<00:00,  1.80it/s, loss=0.025, v_num=3, val_loss=0.0552, train_loss_step=0.024, train_loss_epoch=0.0256]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 58: 100%|██████████| 31/31 [00:16<00:00,  1.85it/s, loss=0.025, v_num=3, val_loss=0.0555, train_loss_step=0.0274, train_loss_epoch=0.0248]\n",
      "Epoch 59:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=0.025, v_num=3, val_loss=0.0555, train_loss_step=0.0235, train_loss_epoch=0.0248] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 59: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.025, v_num=3, val_loss=0.0551, train_loss_step=0.0266, train_loss_epoch=0.0248]\n",
      "Epoch 60:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.0252, v_num=3, val_loss=0.0551, train_loss_step=0.0245, train_loss_epoch=0.0248]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 60: 100%|██████████| 31/31 [00:16<00:00,  1.84it/s, loss=0.0252, v_num=3, val_loss=0.0553, train_loss_step=0.0267, train_loss_epoch=0.025] \n",
      "Epoch 61:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.0251, v_num=3, val_loss=0.0553, train_loss_step=0.024, train_loss_epoch=0.025] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 61: 100%|██████████| 31/31 [00:16<00:00,  1.84it/s, loss=0.0251, v_num=3, val_loss=0.0553, train_loss_step=0.0244, train_loss_epoch=0.0252]\n",
      "Epoch 62:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.0253, v_num=3, val_loss=0.0553, train_loss_step=0.0267, train_loss_epoch=0.0252]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 62: 100%|██████████| 31/31 [00:16<00:00,  1.83it/s, loss=0.0253, v_num=3, val_loss=0.0551, train_loss_step=0.0249, train_loss_epoch=0.0252]\n",
      "Epoch 63:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.0246, v_num=3, val_loss=0.0551, train_loss_step=0.023, train_loss_epoch=0.0252] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 63: 100%|██████████| 31/31 [00:16<00:00,  1.84it/s, loss=0.0246, v_num=3, val_loss=0.0552, train_loss_step=0.0258, train_loss_epoch=0.0247]\n",
      "Epoch 64:  97%|█████████▋| 30/31 [00:16<00:00,  1.80it/s, loss=0.0247, v_num=3, val_loss=0.0552, train_loss_step=0.0244, train_loss_epoch=0.0247]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 64: 100%|██████████| 31/31 [00:16<00:00,  1.85it/s, loss=0.0247, v_num=3, val_loss=0.0553, train_loss_step=0.0268, train_loss_epoch=0.0249]\n",
      "Epoch 65:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=0.0254, v_num=3, val_loss=0.0553, train_loss_step=0.0267, train_loss_epoch=0.0249]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65: 100%|██████████| 31/31 [00:16<00:00,  1.82it/s, loss=0.0254, v_num=3, val_loss=0.0552, train_loss_step=0.0264, train_loss_epoch=0.0252]\n",
      "Epoch 66:  97%|█████████▋| 30/31 [00:16<00:00,  1.80it/s, loss=0.0249, v_num=3, val_loss=0.0552, train_loss_step=0.0246, train_loss_epoch=0.0252]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66: 100%|██████████| 31/31 [00:16<00:00,  1.85it/s, loss=0.0249, v_num=3, val_loss=0.0552, train_loss_step=0.0244, train_loss_epoch=0.0249]\n",
      "Epoch 67:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.0249, v_num=3, val_loss=0.0552, train_loss_step=0.0221, train_loss_epoch=0.0249]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.0249, v_num=3, val_loss=0.0553, train_loss_step=0.026, train_loss_epoch=0.025]  \n",
      "Epoch 68:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.0246, v_num=3, val_loss=0.0553, train_loss_step=0.0241, train_loss_epoch=0.025]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68: 100%|██████████| 31/31 [00:16<00:00,  1.84it/s, loss=0.0246, v_num=3, val_loss=0.0553, train_loss_step=0.0224, train_loss_epoch=0.0248]\n",
      "Epoch 69:  97%|█████████▋| 30/31 [00:16<00:00,  1.82it/s, loss=0.0246, v_num=3, val_loss=0.0553, train_loss_step=0.0243, train_loss_epoch=0.0248]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 69: 100%|██████████| 31/31 [00:16<00:00,  1.87it/s, loss=0.0246, v_num=3, val_loss=0.0552, train_loss_step=0.0251, train_loss_epoch=0.0248]\n",
      "Epoch 69: 100%|██████████| 31/31 [00:16<00:00,  1.87it/s, loss=0.0246, v_num=3, val_loss=0.0552, train_loss_step=0.0251, train_loss_epoch=0.0248]\n",
      "[21, 19, 50, 49, 20, 51, 30, 36, 28, 59, 5, 60, 16, 24]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | SMAPE                           | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 715   \n",
      "3  | prescalers                         | ModuleDict                      | 224   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.1 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 19.2 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 17.1 K\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K\n",
      "11 | lstm_encoder                       | LSTM                            | 33.3 K\n",
      "12 | lstm_decoder                       | LSTM                            | 33.3 K\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128   \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K \n",
      "20 | output_layer                       | Linear                          | 65    \n",
      "----------------------------------------------------------------------------------------\n",
      "253 K     Trainable params\n",
      "0         Non-trainable params\n",
      "253 K     Total params\n",
      "1.012     Total estimated model params size (MB)\n",
      "                                                              /home/joeunchan/anaconda3/envs/torch1/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s] /home/joeunchan/anaconda3/envs/torch1/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  97%|█████████▋| 30/31 [00:16<00:00,  1.81it/s, loss=0.124, v_num=4, val_loss=0.182, train_loss_step=0.120]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 31/31 [00:16<00:00,  1.86it/s, loss=0.124, v_num=4, val_loss=0.126, train_loss_step=0.110, train_loss_epoch=0.135]\n",
      "Epoch 1:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.101, v_num=4, val_loss=0.126, train_loss_step=0.0906, train_loss_epoch=0.135]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 31/31 [00:16<00:00,  1.84it/s, loss=0.101, v_num=4, val_loss=0.108, train_loss_step=0.0908, train_loss_epoch=0.105]\n",
      "Epoch 2:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=0.0805, v_num=4, val_loss=0.108, train_loss_step=0.0694, train_loss_epoch=0.105]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 31/31 [00:16<00:00,  1.82it/s, loss=0.0805, v_num=4, val_loss=0.0995, train_loss_step=0.0793, train_loss_epoch=0.0835]\n",
      "Epoch 3:  97%|█████████▋| 30/31 [00:16<00:00,  1.80it/s, loss=0.0718, v_num=4, val_loss=0.0995, train_loss_step=0.0687, train_loss_epoch=0.0835]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 31/31 [00:16<00:00,  1.84it/s, loss=0.0718, v_num=4, val_loss=0.0939, train_loss_step=0.0688, train_loss_epoch=0.0716]\n",
      "Epoch 4:  97%|█████████▋| 30/31 [00:16<00:00,  1.81it/s, loss=0.0619, v_num=4, val_loss=0.0939, train_loss_step=0.0626, train_loss_epoch=0.0716]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 31/31 [00:16<00:00,  1.86it/s, loss=0.0619, v_num=4, val_loss=0.0777, train_loss_step=0.0651, train_loss_epoch=0.0636]\n",
      "Epoch 5:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.058, v_num=4, val_loss=0.0777, train_loss_step=0.0569, train_loss_epoch=0.0636] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.058, v_num=4, val_loss=0.076, train_loss_step=0.0591, train_loss_epoch=0.0583] \n",
      "Epoch 6:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.0558, v_num=4, val_loss=0.076, train_loss_step=0.0599, train_loss_epoch=0.0583]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.0558, v_num=4, val_loss=0.0801, train_loss_step=0.0649, train_loss_epoch=0.0554]\n",
      "Epoch 7:  97%|█████████▋| 30/31 [00:17<00:00,  1.76it/s, loss=0.0546, v_num=4, val_loss=0.0801, train_loss_step=0.0566, train_loss_epoch=0.0554]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 31/31 [00:17<00:00,  1.80it/s, loss=0.0546, v_num=4, val_loss=0.0717, train_loss_step=0.0488, train_loss_epoch=0.0544]\n",
      "Epoch 8:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.0479, v_num=4, val_loss=0.0717, train_loss_step=0.0516, train_loss_epoch=0.0544]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 31/31 [00:16<00:00,  1.84it/s, loss=0.0479, v_num=4, val_loss=0.0663, train_loss_step=0.0511, train_loss_epoch=0.0487]\n",
      "Epoch 9:  97%|█████████▋| 30/31 [00:16<00:00,  1.80it/s, loss=0.0447, v_num=4, val_loss=0.0663, train_loss_step=0.0435, train_loss_epoch=0.0487]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 31/31 [00:16<00:00,  1.85it/s, loss=0.0447, v_num=4, val_loss=0.0646, train_loss_step=0.0422, train_loss_epoch=0.0454]\n",
      "Epoch 10:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=0.0422, v_num=4, val_loss=0.0646, train_loss_step=0.0459, train_loss_epoch=0.0454]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 31/31 [00:16<00:00,  1.83it/s, loss=0.0422, v_num=4, val_loss=0.0648, train_loss_step=0.0447, train_loss_epoch=0.0422]\n",
      "Epoch 11:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.0423, v_num=4, val_loss=0.0648, train_loss_step=0.0436, train_loss_epoch=0.0422]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.0423, v_num=4, val_loss=0.0644, train_loss_step=0.0445, train_loss_epoch=0.0423]\n",
      "Epoch 12:  97%|█████████▋| 30/31 [00:17<00:00,  1.76it/s, loss=0.0384, v_num=4, val_loss=0.0644, train_loss_step=0.0382, train_loss_epoch=0.0423]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 31/31 [00:17<00:00,  1.80it/s, loss=0.0384, v_num=4, val_loss=0.0659, train_loss_step=0.0389, train_loss_epoch=0.0389]\n",
      "Epoch 13:  97%|█████████▋| 30/31 [00:16<00:00,  1.78it/s, loss=0.039, v_num=4, val_loss=0.0659, train_loss_step=0.037, train_loss_epoch=0.0389]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 31/31 [00:16<00:00,  1.83it/s, loss=0.039, v_num=4, val_loss=0.0676, train_loss_step=0.0408, train_loss_epoch=0.0381]\n",
      "Epoch 14:  97%|█████████▋| 30/31 [00:16<00:00,  1.80it/s, loss=0.0359, v_num=4, val_loss=0.0676, train_loss_step=0.0361, train_loss_epoch=0.0381]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 31/31 [00:16<00:00,  1.85it/s, loss=0.0359, v_num=4, val_loss=0.0688, train_loss_step=0.0316, train_loss_epoch=0.0362]\n",
      "Epoch 15:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.0376, v_num=4, val_loss=0.0688, train_loss_step=0.0399, train_loss_epoch=0.0362]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 31/31 [00:16<00:00,  1.83it/s, loss=0.0376, v_num=4, val_loss=0.0688, train_loss_step=0.0405, train_loss_epoch=0.0372]\n",
      "Epoch 16:  97%|█████████▋| 30/31 [00:16<00:00,  1.81it/s, loss=0.0367, v_num=4, val_loss=0.0688, train_loss_step=0.0348, train_loss_epoch=0.0372]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 31/31 [00:16<00:00,  1.85it/s, loss=0.0367, v_num=4, val_loss=0.0684, train_loss_step=0.0359, train_loss_epoch=0.0369]\n",
      "Epoch 17:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.0323, v_num=4, val_loss=0.0684, train_loss_step=0.0327, train_loss_epoch=0.0369]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 31/31 [00:16<00:00,  1.83it/s, loss=0.0323, v_num=4, val_loss=0.0682, train_loss_step=0.0318, train_loss_epoch=0.0324]\n",
      "Epoch 18:  97%|█████████▋| 30/31 [00:16<00:00,  1.79it/s, loss=0.0328, v_num=4, val_loss=0.0682, train_loss_step=0.030, train_loss_epoch=0.0324] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 31/31 [00:16<00:00,  1.84it/s, loss=0.0328, v_num=4, val_loss=0.0687, train_loss_step=0.0335, train_loss_epoch=0.033]\n",
      "Epoch 19:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.0313, v_num=4, val_loss=0.0687, train_loss_step=0.0298, train_loss_epoch=0.033]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.0313, v_num=4, val_loss=0.0683, train_loss_step=0.030, train_loss_epoch=0.0309]\n",
      "Epoch 20:  97%|█████████▋| 30/31 [00:16<00:00,  1.77it/s, loss=0.0311, v_num=4, val_loss=0.0683, train_loss_step=0.0326, train_loss_epoch=0.0309]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 31/31 [00:17<00:00,  1.82it/s, loss=0.0311, v_num=4, val_loss=0.0678, train_loss_step=0.0327, train_loss_epoch=0.0314]\n",
      "Epoch 21:  97%|█████████▋| 30/31 [00:17<00:00,  1.75it/s, loss=0.0305, v_num=4, val_loss=0.0678, train_loss_step=0.0277, train_loss_epoch=0.0314]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|██████████| 31/31 [00:17<00:00,  1.80it/s, loss=0.0305, v_num=4, val_loss=0.0677, train_loss_step=0.0306, train_loss_epoch=0.0302]\n",
      "Epoch 21: 100%|██████████| 31/31 [00:17<00:00,  1.80it/s, loss=0.0305, v_num=4, val_loss=0.0677, train_loss_step=0.0306, train_loss_epoch=0.0302]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0, 5):    \n",
    "\n",
    "    print(group[idx])\n",
    "\n",
    "    data = data_bag[idx]\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    max_prediction_length = 168\n",
    "    max_encoder_length = 336\n",
    "    training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "    training = TimeSeriesDataSet(\n",
    "        data[lambda x: x.time_idx <= training_cutoff],\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"kWH\",\n",
    "        group_ids=[\"num\"],\n",
    "        min_encoder_length=max_encoder_length,\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=max_prediction_length,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=[\"num\", \"energy_group\"],\n",
    "        static_reals=[\"non_electric_aircondition\", \"sunlight\"],\n",
    "        time_varying_known_categoricals=[\"day_of_Week\", \"day_of_month\", \"24Hour\", \"holiday\", \"Weekend\", \"hour_cat\"],\n",
    "        time_varying_known_reals=[\"C\", \"m/s\", \"wet\", \"mm\", \"hr\", \"time_idx\", \"discomfort_real\"],\n",
    "        time_varying_unknown_categoricals=[],\n",
    "        time_varying_unknown_reals=[\"kWH\"],\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True\n",
    "    )\n",
    "\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "    batch_size = 64  # set this between 32 to 128\n",
    "    train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "    val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "    lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "    logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=500,\n",
    "        gpus=1,\n",
    "        weights_summary=\"top\",\n",
    "        gradient_clip_val=0.14,\n",
    "        limit_train_batches=30, \n",
    "        callbacks=[lr_logger, early_stop_callback],\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "\n",
    "    tft = TemporalFusionTransformer.from_dataset(\n",
    "        training,\n",
    "        learning_rate=0.03,\n",
    "        hidden_size=64,\n",
    "        lstm_layers = 1,\n",
    "        attention_head_size=4,\n",
    "        dropout=0.15,\n",
    "        hidden_continuous_size=8,\n",
    "        output_size=1,\n",
    "        loss=SMAPE(),\n",
    "        log_interval=0,\n",
    "        reduce_on_plateau_patience=4,\n",
    "    )\n",
    "\n",
    "    # fit network\n",
    "    trainer.fit(\n",
    "        tft,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd02625b230b0936c03a7a859dabe4a10a429313c958b60e79e367b6eadd1f82f0b",
   "display_name": "Python 3.9.1 64-bit ('torch1': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}